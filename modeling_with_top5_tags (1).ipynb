{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>MPST: A Corpus of Movie Plot Synopses with Tags</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/krushithreddy0817/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm\n",
    "\n",
    "import nltk\n",
    "from itertools import combinations\n",
    "#from toolz import compose\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import sent_tokenize\n",
    "stemmer = SnowballStemmer('english')\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,hamming_loss\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>cnt_dup</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>synopsis_count</th>\n",
       "      <th>synopsis_sent_count</th>\n",
       "      <th>CleanedSynopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "      <td>Set in Hamburg, West Germany, several criminal...</td>\n",
       "      <td>murder</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>26</td>\n",
       "      <td>set hamburg west germani sever crimin take adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$windle</td>\n",
       "      <td>A 6th grader named Griffin Bing decides to gat...</td>\n",
       "      <td>flashback</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>14</td>\n",
       "      <td>grader name griffin bing decid gather entir gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'71</td>\n",
       "      <td>Gary Hook, a new recruit to the British Army, ...</td>\n",
       "      <td>suspenseful, neo noir, murder, violence</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>gari hook new recruit british armi take leav m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'A' gai wak</td>\n",
       "      <td>Sergeant Dragon Ma (Jackie Chan) is part of th...</td>\n",
       "      <td>cult, violence</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>665</td>\n",
       "      <td>41</td>\n",
       "      <td>sergeant dragon jacki chan part hong kong mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Breaker' Morant</td>\n",
       "      <td>In Pretoria, South Africa, in 1902, Major Char...</td>\n",
       "      <td>murder, anti war, violence, flashback, tragedy...</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1694</td>\n",
       "      <td>140</td>\n",
       "      <td>pretoria south africa major charl bolton rod m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                      plot_synopsis  \\\n",
       "0                 $  Set in Hamburg, West Germany, several criminal...   \n",
       "1           $windle  A 6th grader named Griffin Bing decides to gat...   \n",
       "2               '71  Gary Hook, a new recruit to the British Army, ...   \n",
       "3       'A' gai wak  Sergeant Dragon Ma (Jackie Chan) is part of th...   \n",
       "4  'Breaker' Morant  In Pretoria, South Africa, in 1902, Major Char...   \n",
       "\n",
       "                                                tags  split synopsis_source  \\\n",
       "0                                             murder   test            imdb   \n",
       "1                                          flashback  train       wikipedia   \n",
       "2            suspenseful, neo noir, murder, violence  train       wikipedia   \n",
       "3                                     cult, violence  train       wikipedia   \n",
       "4  murder, anti war, violence, flashback, tragedy...  train       wikipedia   \n",
       "\n",
       "   cnt_dup  tag_count  synopsis_count  synopsis_sent_count  \\\n",
       "0        1          1             648                   26   \n",
       "1        1          1             353                   14   \n",
       "2        1          4             699                   39   \n",
       "3        1          2             665                   41   \n",
       "4        1          6            1694                  140   \n",
       "\n",
       "                                     CleanedSynopsis  \n",
       "0  set hamburg west germani sever crimin take adv...  \n",
       "1  grader name griffin bing decid gather entir gr...  \n",
       "2  gari hook new recruit british armi take leav m...  \n",
       "3  sergeant dragon jacki chan part hong kong mari...  \n",
       "4  pretoria south africa major charl bolton rod m...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"cleaned_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('cleaned_data.db')\n",
    "data.to_sql('cleaned_data', conn, if_exists='replace', index=False)\n",
    "train = pd.read_sql(\"Select * From cleaned_data where split = 'train' OR split='val'\",conn)\n",
    "test =  pd.read_sql(\"Select * From cleaned_data where split = 'test'\",conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              title                                      plot_synopsis  \\\n",
      "0           $windle  A 6th grader named Griffin Bing decides to gat...   \n",
      "1               '71  Gary Hook, a new recruit to the British Army, ...   \n",
      "2       'A' gai wak  Sergeant Dragon Ma (Jackie Chan) is part of th...   \n",
      "3  'Breaker' Morant  In Pretoria, South Africa, in 1902, Major Char...   \n",
      "4           'C'-Man  Customs Investigator Cliff Holden (Dean Jagger...   \n",
      "\n",
      "                                                tags  split synopsis_source  \\\n",
      "0                                          flashback  train       wikipedia   \n",
      "1            suspenseful, neo noir, murder, violence  train       wikipedia   \n",
      "2                                     cult, violence  train       wikipedia   \n",
      "3  murder, anti war, violence, flashback, tragedy...  train       wikipedia   \n",
      "4                                             murder  train            imdb   \n",
      "\n",
      "   cnt_dup  tag_count  synopsis_count  synopsis_sent_count  \\\n",
      "0        1          1             353                   14   \n",
      "1        1          4             699                   39   \n",
      "2        1          2             665                   41   \n",
      "3        1          6            1694                  140   \n",
      "4        1          1            1421                  102   \n",
      "\n",
      "                                     CleanedSynopsis  \n",
      "0  grader name griffin bing decid gather entir gr...  \n",
      "1  gari hook new recruit british armi take leav m...  \n",
      "2  sergeant dragon jacki chan part hong kong mari...  \n",
      "3  pretoria south africa major charl bolton rod m...  \n",
      "4  custom investig cliff holden dean jagger retur...  \n",
      "(11027, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             title  \\\n",
      "0                                                $   \n",
      "1                            'Crocodile' Dundee II   \n",
      "2                      'Hukkunud Alpinisti' hotell   \n",
      "3  'Northwest Passage' (Book I -- Rogers' Rangers)   \n",
      "4                             (500) Days of Summer   \n",
      "\n",
      "                                       plot_synopsis  \\\n",
      "0  Set in Hamburg, West Germany, several criminal...   \n",
      "1  A year has passed since the events of Crocodil...   \n",
      "2  Inspector Glebsky arrives at the hotel \"Dead M...   \n",
      "3  === Book 1 ===\\nLangdon Towne is a young Congr...   \n",
      "4  (500) Days of Summer is presented in a non-chr...   \n",
      "\n",
      "                                                tags split synopsis_source  \\\n",
      "0                                             murder  test            imdb   \n",
      "1                                             murder  test       wikipedia   \n",
      "2                             cult, neo noir, murder  test       wikipedia   \n",
      "3           tragedy, revenge, cult, murder, violence  test       wikipedia   \n",
      "4  boring, depressing, stupid, cult, cute, magica...  test            imdb   \n",
      "\n",
      "   cnt_dup  tag_count  synopsis_count  synopsis_sent_count  \\\n",
      "0        1          1             648                   26   \n",
      "1        1          1             550                   25   \n",
      "2        1          3             260                   23   \n",
      "3        1          5            1269                   52   \n",
      "4        1         13            1680                  124   \n",
      "\n",
      "                                     CleanedSynopsis  \n",
      "0  set hamburg west germani sever crimin take adv...  \n",
      "1  year pass sinc event crocodil dunde mick dunde...  \n",
      "2  inspector glebski arriv hotel dead mountain an...  \n",
      "3  book langdon town young congregationalist resi...  \n",
      "4  day summer present non chronolog format scene ...  \n",
      "(2730, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test.head())\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag vectorizaton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cult', 'flashback', 'murder', 'romantic', 'violence']\n"
     ]
    }
   ],
   "source": [
    "tag_vect = CountVectorizer(max_features=5,tokenizer = lambda x: str(x).split(\", \"))\n",
    "y_train = tag_vect.fit_transform(train['tags'])\n",
    "y_test = tag_vect.transform(test['tags'])\n",
    "print(tag_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = tag_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and uni grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize=CountVectorizer()\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 78666)   (11027, 5)\n",
      "(2730, 78666)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:    5.5s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:    6.3s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.48119998679643167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4773, Recall: 0.5197, F1-measure: 0.4976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.36      0.36      0.36       507\n",
      "   flashback       0.27      0.25      0.26       549\n",
      "      murder       0.60      0.66      0.63      1043\n",
      "    romantic       0.42      0.50      0.46       534\n",
      "    violence       0.55      0.63      0.58       827\n",
      "\n",
      "   micro avg       0.48      0.52      0.50      3460\n",
      "   macro avg       0.44      0.48      0.46      3460\n",
      "weighted avg       0.47      0.52      0.49      3460\n",
      " samples avg       0.38      0.40      0.36      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    6.5s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    7.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4635168307036294"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5128, Recall: 0.3922, F1-measure: 0.4445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.38      0.15      0.22       507\n",
      "   flashback       0.29      0.25      0.27       549\n",
      "      murder       0.64      0.52      0.58      1043\n",
      "    romantic       0.48      0.35      0.41       534\n",
      "    violence       0.56      0.49      0.53       827\n",
      "\n",
      "   micro avg       0.51      0.39      0.44      3460\n",
      "   macro avg       0.47      0.35      0.40      3460\n",
      "weighted avg       0.50      0.39      0.44      3460\n",
      " samples avg       0.33      0.30      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.01,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    4.8s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.456738758582612\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5974, Recall: 0.3500, F1-measure: 0.4414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.38      0.12      0.18       507\n",
      "   flashback       0.37      0.13      0.19       549\n",
      "      murder       0.67      0.59      0.63      1043\n",
      "    romantic       0.55      0.27      0.36       534\n",
      "    violence       0.65      0.39      0.48       827\n",
      "\n",
      "   micro avg       0.60      0.35      0.44      3460\n",
      "   macro avg       0.52      0.30      0.37      3460\n",
      "weighted avg       0.56      0.35      0.42      3460\n",
      " samples avg       0.32      0.27      0.27      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and bi grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 89722)   (11027, 5)\n",
      "(2730, 89722)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(2,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    0.8s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    1.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    1.2s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5064083226624995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5160, Recall: 0.4882, F1-measure: 0.5017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.36      0.23      0.28       507\n",
      "   flashback       0.35      0.20      0.26       549\n",
      "      murder       0.64      0.67      0.65      1043\n",
      "    romantic       0.42      0.51      0.46       534\n",
      "    violence       0.55      0.59      0.57       827\n",
      "\n",
      "   micro avg       0.52      0.49      0.50      3460\n",
      "   macro avg       0.46      0.44      0.45      3460\n",
      "weighted avg       0.50      0.49      0.49      3460\n",
      " samples avg       0.38      0.37      0.36      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    3.9s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    4.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4244473126376398\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5099, Recall: 0.3578, F1-measure: 0.4205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.33      0.18      0.23       507\n",
      "   flashback       0.35      0.19      0.25       549\n",
      "      murder       0.61      0.51      0.56      1043\n",
      "    romantic       0.43      0.26      0.33       534\n",
      "    violence       0.56      0.44      0.50       827\n",
      "\n",
      "   micro avg       0.51      0.36      0.42      3460\n",
      "   macro avg       0.46      0.32      0.37      3460\n",
      "weighted avg       0.49      0.36      0.41      3460\n",
      " samples avg       0.29      0.26      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.0001,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    2.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    2.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.42545028451221273\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5491, Recall: 0.3428, F1-measure: 0.4221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.37      0.15      0.21       507\n",
      "   flashback       0.39      0.17      0.24       549\n",
      "      murder       0.63      0.51      0.57      1043\n",
      "    romantic       0.49      0.25      0.33       534\n",
      "    violence       0.59      0.42      0.49       827\n",
      "\n",
      "   micro avg       0.55      0.34      0.42      3460\n",
      "   macro avg       0.49      0.30      0.37      3460\n",
      "weighted avg       0.52      0.34      0.41      3460\n",
      " samples avg       0.28      0.25      0.24      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.001,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and tri grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 200000)   (11027, 5)\n",
      "(2730, 200000)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(3,3),min_df=0.00005,max_features=200000)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    2.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    2.7s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4218685019272745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4648, Recall: 0.3506, F1-measure: 0.3997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.16      0.22       507\n",
      "   flashback       0.26      0.16      0.20       549\n",
      "      murder       0.54      0.61      0.57      1043\n",
      "    romantic       0.34      0.17      0.23       534\n",
      "    violence       0.53      0.38      0.44       827\n",
      "\n",
      "   micro avg       0.46      0.35      0.40      3460\n",
      "   macro avg       0.40      0.30      0.33      3460\n",
      "weighted avg       0.43      0.35      0.38      3460\n",
      " samples avg       0.29      0.26      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    2.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    2.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.30817407908054795\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4729, Recall: 0.2092, F1-measure: 0.2901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.39      0.07      0.13       507\n",
      "   flashback       0.31      0.08      0.13       549\n",
      "      murder       0.53      0.37      0.44      1043\n",
      "    romantic       0.36      0.10      0.16       534\n",
      "    violence       0.48      0.25      0.33       827\n",
      "\n",
      "   micro avg       0.47      0.21      0.29      3460\n",
      "   macro avg       0.42      0.17      0.23      3460\n",
      "weighted avg       0.44      0.21      0.27      3460\n",
      " samples avg       0.19      0.15      0.16      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    1.0s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.31994673261456696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    1.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4721, Recall: 0.2347, F1-measure: 0.3135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.41      0.09      0.15       507\n",
      "   flashback       0.30      0.09      0.14       549\n",
      "      murder       0.54      0.42      0.47      1043\n",
      "    romantic       0.37      0.17      0.23       534\n",
      "    violence       0.49      0.23      0.31       827\n",
      "\n",
      "   micro avg       0.47      0.23      0.31      3460\n",
      "   macro avg       0.42      0.20      0.26      3460\n",
      "weighted avg       0.44      0.23      0.30      3460\n",
      " samples avg       0.21      0.17      0.18      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and uni,bi grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 109114)   (11027, 5)\n",
      "(2730, 109114)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(1,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    5.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    5.8s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5112386180635963\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5008, Recall: 0.5390, F1-measure: 0.5192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.36      0.34      0.35       507\n",
      "   flashback       0.31      0.26      0.28       549\n",
      "      murder       0.65      0.68      0.66      1043\n",
      "    romantic       0.43      0.58      0.49       534\n",
      "    violence       0.56      0.64      0.60       827\n",
      "\n",
      "   micro avg       0.50      0.54      0.52      3460\n",
      "   macro avg       0.46      0.50      0.48      3460\n",
      "weighted avg       0.50      0.54      0.51      3460\n",
      " samples avg       0.39      0.41      0.37      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    6.3s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    7.4s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.459049045715355\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5078, Recall: 0.3968, F1-measure: 0.4455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.16      0.22       507\n",
      "   flashback       0.29      0.27      0.28       549\n",
      "      murder       0.63      0.53      0.58      1043\n",
      "    romantic       0.47      0.39      0.43       534\n",
      "    violence       0.60      0.45      0.52       827\n",
      "\n",
      "   micro avg       0.51      0.40      0.45      3460\n",
      "   macro avg       0.47      0.36      0.40      3460\n",
      "weighted avg       0.50      0.40      0.44      3460\n",
      " samples avg       0.33      0.30      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.01,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    4.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    5.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4604806856578431\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6243, Recall: 0.3549, F1-measure: 0.4526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.46      0.16      0.23       507\n",
      "   flashback       0.38      0.07      0.13       549\n",
      "      murder       0.67      0.62      0.64      1043\n",
      "    romantic       0.58      0.26      0.36       534\n",
      "    violence       0.68      0.39      0.50       827\n",
      "\n",
      "   micro avg       0.62      0.35      0.45      3460\n",
      "   macro avg       0.55      0.30      0.37      3460\n",
      "weighted avg       0.58      0.35      0.42      3460\n",
      " samples avg       0.33      0.27      0.28      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and uni,bi,tri grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 114151)   (11027, 5)\n",
      "(2730, 114151)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(1,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    5.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    6.5s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5111489199548436\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5028, Recall: 0.5361, F1-measure: 0.5190\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.37      0.34      0.35       507\n",
      "   flashback       0.32      0.27      0.29       549\n",
      "      murder       0.64      0.67      0.66      1043\n",
      "    romantic       0.42      0.57      0.49       534\n",
      "    violence       0.56      0.63      0.60       827\n",
      "\n",
      "   micro avg       0.50      0.54      0.52      3460\n",
      "   macro avg       0.46      0.50      0.48      3460\n",
      "weighted avg       0.50      0.54      0.51      3460\n",
      " samples avg       0.39      0.41      0.37      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    6.6s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    7.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4578162209987625\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6259, Recall: 0.3708, F1-measure: 0.4657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.46      0.11      0.18       507\n",
      "   flashback       0.40      0.05      0.08       549\n",
      "      murder       0.66      0.62      0.64      1043\n",
      "    romantic       0.58      0.28      0.37       534\n",
      "    violence       0.64      0.50      0.56       827\n",
      "\n",
      "   micro avg       0.63      0.37      0.47      3460\n",
      "   macro avg       0.55      0.31      0.37      3460\n",
      "weighted avg       0.57      0.37      0.42      3460\n",
      " samples avg       0.34      0.28      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    4.4s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    5.5s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4573853058896979\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6071, Recall: 0.3751, F1-measure: 0.4637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.42      0.14      0.21       507\n",
      "   flashback       0.34      0.04      0.07       549\n",
      "      murder       0.64      0.66      0.65      1043\n",
      "    romantic       0.56      0.27      0.36       534\n",
      "    violence       0.65      0.46      0.54       827\n",
      "\n",
      "   micro avg       0.61      0.38      0.46      3460\n",
      "   macro avg       0.52      0.31      0.37      3460\n",
      "weighted avg       0.55      0.38      0.42      3460\n",
      " samples avg       0.35      0.29      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and tri grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 10726)   (11027, 5)\n",
      "(2730, 10726)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(3,3),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    9.8s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   10.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=2.5, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4907140280954945\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4397, Recall: 0.5815, F1-measure: 0.5007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.48      0.37       507\n",
      "   flashback       0.26      0.35      0.30       549\n",
      "      murder       0.61      0.65      0.63      1043\n",
      "    romantic       0.39      0.65      0.48       534\n",
      "    violence       0.53      0.67      0.59       827\n",
      "\n",
      "   micro avg       0.44      0.58      0.50      3460\n",
      "   macro avg       0.42      0.56      0.48      3460\n",
      "weighted avg       0.46      0.58      0.51      3460\n",
      " samples avg       0.38      0.45      0.38      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=2.5),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   13.0s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   15.7s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   15.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.44703851462712957\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5285, Recall: 0.4208, F1-measure: 0.4685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.35      0.25      0.29       507\n",
      "   flashback       0.32      0.10      0.15       549\n",
      "      murder       0.61      0.71      0.66      1043\n",
      "    romantic       0.43      0.46      0.45       534\n",
      "    violence       0.65      0.35      0.46       827\n",
      "\n",
      "   micro avg       0.53      0.42      0.47      3460\n",
      "   macro avg       0.47      0.37      0.40      3460\n",
      "weighted avg       0.51      0.42      0.44      3460\n",
      " samples avg       0.36      0.33      0.32      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    9.4s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   11.7s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4354080374389804\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4733, Recall: 0.4040, F1-measure: 0.4359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.32      0.41      0.36       507\n",
      "   flashback       0.27      0.02      0.03       549\n",
      "      murder       0.62      0.49      0.55      1043\n",
      "    romantic       0.48      0.20      0.28       534\n",
      "    violence       0.46      0.68      0.55       827\n",
      "\n",
      "   micro avg       0.47      0.40      0.44      3460\n",
      "   macro avg       0.43      0.36      0.35      3460\n",
      "weighted avg       0.46      0.40      0.40      3460\n",
      " samples avg       0.32      0.30      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.0001,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 82528)   (11027, 5)\n",
      "(2730, 82528)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(4,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   25.8s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   28.2s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=2, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4985966981889413\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4739, Recall: 0.5442, F1-measure: 0.5067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.37      0.35       507\n",
      "   flashback       0.29      0.30      0.30       549\n",
      "      murder       0.62      0.66      0.64      1043\n",
      "    romantic       0.41      0.57      0.48       534\n",
      "    violence       0.55      0.66      0.60       827\n",
      "\n",
      "   micro avg       0.47      0.54      0.51      3460\n",
      "   macro avg       0.44      0.51      0.47      3460\n",
      "weighted avg       0.47      0.54      0.51      3460\n",
      " samples avg       0.38      0.42      0.37      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=2),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   24.7s remaining:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   29.9s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4546875019057356\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5287, Recall: 0.3780, F1-measure: 0.4408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.19      0.24       507\n",
      "   flashback       0.31      0.12      0.17       549\n",
      "      murder       0.65      0.55      0.59      1043\n",
      "    romantic       0.43      0.39      0.41       534\n",
      "    violence       0.61      0.44      0.51       827\n",
      "\n",
      "   micro avg       0.53      0.38      0.44      3460\n",
      "   macro avg       0.47      0.34      0.39      3460\n",
      "weighted avg       0.50      0.38      0.43      3460\n",
      " samples avg       0.34      0.30      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   18.7s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   23.0s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.44909550240263113\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4742, Recall: 0.4656, F1-measure: 0.4699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.12      0.18       507\n",
      "   flashback       0.28      0.34      0.31       549\n",
      "      murder       0.57      0.68      0.62      1043\n",
      "    romantic       0.42      0.40      0.41       534\n",
      "    violence       0.56      0.53      0.54       827\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      3460\n",
      "   macro avg       0.43      0.41      0.41      3460\n",
      "weighted avg       0.46      0.47      0.45      3460\n",
      " samples avg       0.36      0.36      0.33      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and three,four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93254)   (11027, 5)\n",
      "(2730, 93254)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(3,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   42.2s remaining:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   43.4s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4986242988074304\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4521, Recall: 0.5659, F1-measure: 0.5026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.42      0.36       507\n",
      "   flashback       0.28      0.35      0.31       549\n",
      "      murder       0.62      0.65      0.63      1043\n",
      "    romantic       0.39      0.61      0.48       534\n",
      "    violence       0.54      0.66      0.59       827\n",
      "\n",
      "   micro avg       0.45      0.57      0.50      3460\n",
      "   macro avg       0.43      0.54      0.47      3460\n",
      "weighted avg       0.46      0.57      0.51      3460\n",
      " samples avg       0.38      0.43      0.37      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   40.2s remaining:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   48.6s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   48.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   48.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4419158675303263\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5768, Recall: 0.3829, F1-measure: 0.4603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.36      0.24      0.29       507\n",
      "   flashback       0.36      0.18      0.24       549\n",
      "      murder       0.67      0.61      0.64      1043\n",
      "    romantic       0.61      0.22      0.32       534\n",
      "    violence       0.64      0.43      0.52       827\n",
      "\n",
      "   micro avg       0.58      0.38      0.46      3460\n",
      "   macro avg       0.53      0.33      0.40      3460\n",
      "weighted avg       0.56      0.38      0.44      3460\n",
      " samples avg       0.32      0.29      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   29.4s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   35.8s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   36.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4528211054398194\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4617, Recall: 0.4896, F1-measure: 0.4752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.45      0.37       507\n",
      "   flashback       0.34      0.06      0.10       549\n",
      "      murder       0.55      0.66      0.60      1043\n",
      "    romantic       0.48      0.25      0.33       534\n",
      "    violence       0.46      0.74      0.57       827\n",
      "\n",
      "   micro avg       0.46      0.49      0.48      3460\n",
      "   macro avg       0.43      0.43      0.39      3460\n",
      "weighted avg       0.45      0.49      0.44      3460\n",
      " samples avg       0.35      0.37      0.33      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and bi,tri,four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93963)   (11027, 5)\n",
      "(2730, 93963)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   39.3s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   46.0s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   46.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4984526994035465\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4516, Recall: 0.5691, F1-measure: 0.5036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.44      0.37       507\n",
      "   flashback       0.28      0.35      0.31       549\n",
      "      murder       0.62      0.65      0.63      1043\n",
      "    romantic       0.40      0.61      0.48       534\n",
      "    violence       0.53      0.66      0.59       827\n",
      "\n",
      "   micro avg       0.45      0.57      0.50      3460\n",
      "   macro avg       0.43      0.54      0.48      3460\n",
      "weighted avg       0.46      0.57      0.51      3460\n",
      " samples avg       0.38      0.44      0.38      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   43.4s remaining:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   52.8s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   53.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   53.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.43778056242486424\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4055, Recall: 0.3725, F1-measure: 0.3883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.32      0.04      0.08       507\n",
      "   flashback       0.24      0.72      0.36       549\n",
      "      murder       0.70      0.35      0.47      1043\n",
      "    romantic       0.53      0.13      0.21       534\n",
      "    violence       0.56      0.52      0.54       827\n",
      "\n",
      "   micro avg       0.41      0.37      0.39      3460\n",
      "   macro avg       0.47      0.35      0.33      3460\n",
      "weighted avg       0.51      0.37      0.37      3460\n",
      " samples avg       0.28      0.28      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   32.2s remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   39.8s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   40.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   40.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.45684002261740947\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3950, Recall: 0.4454, F1-measure: 0.4187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.27      0.01      0.01       507\n",
      "   flashback       0.30      0.09      0.14       549\n",
      "      murder       0.74      0.33      0.46      1043\n",
      "    romantic       0.29      0.72      0.41       534\n",
      "    violence       0.39      0.92      0.55       827\n",
      "\n",
      "   micro avg       0.40      0.45      0.42      3460\n",
      "   macro avg       0.40      0.41      0.32      3460\n",
      "weighted avg       0.45      0.45      0.36      3460\n",
      " samples avg       0.37      0.35      0.33      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and one,bi,tri,four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93990)   (11027, 5)\n",
      "(2730, 93990)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(1,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   44.9s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   45.7s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   48.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4985583137938495\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4508, Recall: 0.5688, F1-measure: 0.5029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.44      0.37       507\n",
      "   flashback       0.28      0.35      0.31       549\n",
      "      murder       0.62      0.65      0.63      1043\n",
      "    romantic       0.39      0.61      0.48       534\n",
      "    violence       0.53      0.66      0.59       827\n",
      "\n",
      "   micro avg       0.45      0.57      0.50      3460\n",
      "   macro avg       0.43      0.54      0.48      3460\n",
      "weighted avg       0.46      0.57      0.51      3460\n",
      " samples avg       0.38      0.44      0.37      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   45.7s remaining:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   54.1s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.43318323519632623\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3698, Recall: 0.4098, F1-measure: 0.3888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.21      0.93      0.34       507\n",
      "   flashback       0.00      0.00      0.00       549\n",
      "      murder       0.70      0.45      0.55      1043\n",
      "    romantic       0.49      0.46      0.47       534\n",
      "    violence       0.64      0.28      0.39       827\n",
      "\n",
      "   micro avg       0.37      0.41      0.39      3460\n",
      "   macro avg       0.41      0.42      0.35      3460\n",
      "weighted avg       0.47      0.41      0.38      3460\n",
      " samples avg       0.31      0.31      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   34.0s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   41.2s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   41.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   41.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=2, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4420668959397315\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3608, Recall: 0.3806, F1-measure: 0.3705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.38      0.14      0.21       507\n",
      "   flashback       0.22      0.87      0.35       549\n",
      "      murder       0.73      0.28      0.40      1043\n",
      "    romantic       1.00      0.00      0.00       534\n",
      "    violence       0.54      0.58      0.56       827\n",
      "\n",
      "   micro avg       0.36      0.38      0.37      3460\n",
      "   macro avg       0.57      0.37      0.30      3460\n",
      "weighted avg       0.59      0.38      0.34      3460\n",
      " samples avg       0.27      0.27      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=2,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorization with word analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  1,1   |  0.497   |       1        |\n",
      "|  SGDClassifier(log)  |  1,1   |  0.444   |      0.01      |\n",
      "| SGDClassifier(hinge) |  1,1   |  0.441   |      0.1       |\n",
      "|    MultinomialNB     |  2,2   |  0.501   |       1        |\n",
      "|  SGDClassifier(log)  |  2,2   |  0.420   |     0.0001     |\n",
      "| SGDClassifier(hinge) |  2,2   |  0.422   |     0.001      |\n",
      "|    MultinomialNB     |  3,3   |  0.399   |       1        |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.290   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.313   |     1e-05      |\n",
      "|    MultinomialNB     |  1,2   |   0.52   |       1        |\n",
      "|  SGDClassifier(log)  |  1,2   |  0.445   |      0.01      |\n",
      "| SGDClassifier(hinge) |  1,2   |  0.452   |      0.1       |\n",
      "|    MultinomialNB     |  1,3   |   0.52   |       1        |\n",
      "|  SGDClassifier(log)  |  1,3   |  0.465   |      0.1       |\n",
      "| SGDClassifier(hinge) |  1,3   |  0.463   |      0.1       |\n",
      "+----------------------+--------+----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "print(\"CountVectorization with word analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','1,1','0.497','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,1','0.444','0.01'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,1','0.441','0.1'])\n",
    "table.add_row(['MultinomialNB','2,2','0.501','1'])\n",
    "table.add_row(['SGDClassifier(log)','2,2','0.420','0.0001'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,2','0.422','0.001'])\n",
    "table.add_row(['MultinomialNB','3,3','0.399','1'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.290','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.313','1e-05'])\n",
    "table.add_row(['MultinomialNB','1,2','0.52','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,2','0.445','0.01'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,2','0.452','0.1'])\n",
    "table.add_row(['MultinomialNB','1,3','0.52','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,3','0.465','0.1'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,3','0.463','0.1'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorization with char analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  3,3   |  0.500   |      2.5       |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.468   |       1        |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.435   |     0.0001     |\n",
      "|    MultinomialNB     |  4,4   |  0.506   |       2        |\n",
      "|  SGDClassifier(log)  |  4,4   |  0.440   |      0.1       |\n",
      "| SGDClassifier(hinge) |  4,4   |  0.469   |      0.1       |\n",
      "|    MultinomialNB     |  3,4   |  0.502   |       1        |\n",
      "|  SGDClassifier(log)  |  3,4   |  0.460   |       1        |\n",
      "| SGDClassifier(hinge) |  3,4   |  0.475   |      0.1       |\n",
      "|    MultinomialNB     |  2,4   |  0.503   |       1        |\n",
      "|  SGDClassifier(log)  |  2,4   |  0.388   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  2,4   |  0.418   |      0.1       |\n",
      "|    MultinomialNB     |  1,4   |  0.502   |       1        |\n",
      "|  SGDClassifier(log)  |  1,4   |  0.465   |      0.1       |\n",
      "| SGDClassifier(hinge) |  1,4   |  0.370   |       2        |\n",
      "+----------------------+--------+----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "print(\"CountVectorization with char analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','3,3','0.500','2.5'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.468','1'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.435','0.0001'])\n",
    "table.add_row(['MultinomialNB','4,4','0.506','2'])\n",
    "table.add_row(['SGDClassifier(log)','4,4','0.440','0.1'])\n",
    "table.add_row(['SGDClassifier(hinge)','4,4','0.469','0.1'])\n",
    "table.add_row(['MultinomialNB','3,4','0.502','1'])\n",
    "table.add_row(['SGDClassifier(log)','3,4','0.460','1'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,4','0.475','0.1'])\n",
    "table.add_row(['MultinomialNB','2,4','0.503','1'])\n",
    "table.add_row(['SGDClassifier(log)','2,4','0.388','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,4','0.418','0.1'])\n",
    "table.add_row(['MultinomialNB','1,4','0.502','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,4','0.465','0.1'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,4','0.370','2'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 78666)   (11027, 5)\n",
      "(2730, 78666)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer()\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:    2.7s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:    3.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.38160486978328884\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5359, Recall: 0.2760, F1-measure: 0.3644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.40      0.10      0.16       507\n",
      "   flashback       0.23      0.05      0.08       549\n",
      "      murder       0.58      0.47      0.52      1043\n",
      "    romantic       0.49      0.18      0.26       534\n",
      "    violence       0.58      0.36      0.44       827\n",
      "\n",
      "   micro avg       0.54      0.28      0.36      3460\n",
      "   macro avg       0.46      0.23      0.29      3460\n",
      "weighted avg       0.49      0.28      0.34      3460\n",
      " samples avg       0.27      0.21      0.22      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    5.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    6.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4341140828561357"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4758, Recall: 0.4127, F1-measure: 0.4420\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.33      0.25      0.29       507\n",
      "   flashback       0.31      0.27      0.29       549\n",
      "      murder       0.59      0.55      0.57      1043\n",
      "    romantic       0.41      0.33      0.37       534\n",
      "    violence       0.53      0.49      0.51       827\n",
      "\n",
      "   micro avg       0.48      0.41      0.44      3460\n",
      "   macro avg       0.44      0.38      0.40      3460\n",
      "weighted avg       0.47      0.41      0.44      3460\n",
      " samples avg       0.33      0.31      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    5.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.8s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4289163468972529\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4846, Recall: 0.4234, F1-measure: 0.4520\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.28      0.31       507\n",
      "   flashback       0.30      0.23      0.26       549\n",
      "      murder       0.60      0.57      0.58      1043\n",
      "    romantic       0.43      0.36      0.40       534\n",
      "    violence       0.54      0.50      0.52       827\n",
      "\n",
      "   micro avg       0.48      0.42      0.45      3460\n",
      "   macro avg       0.44      0.39      0.41      3460\n",
      "weighted avg       0.48      0.42      0.45      3460\n",
      " samples avg       0.34      0.32      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 89722)   (11027, 5)\n",
      "(2730, 89722)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(2,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    0.8s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    0.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    1.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    1.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.43521252699539387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6381, Recall: 0.3139, F1-measure: 0.4208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.51      0.05      0.09       507\n",
      "   flashback       0.35      0.02      0.04       549\n",
      "      murder       0.67      0.56      0.61      1043\n",
      "    romantic       0.61      0.20      0.30       534\n",
      "    violence       0.63      0.43      0.51       827\n",
      "\n",
      "   micro avg       0.64      0.31      0.42      3460\n",
      "   macro avg       0.55      0.25      0.31      3460\n",
      "weighted avg       0.58      0.31      0.37      3460\n",
      " samples avg       0.29      0.24      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    2.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.39549557869128854\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5837, Recall: 0.2893, F1-measure: 0.3869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.39      0.08      0.14       507\n",
      "   flashback       0.38      0.09      0.15       549\n",
      "      murder       0.65      0.50      0.56      1043\n",
      "    romantic       0.49      0.15      0.23       534\n",
      "    violence       0.61      0.37      0.46       827\n",
      "\n",
      "   micro avg       0.58      0.29      0.39      3460\n",
      "   macro avg       0.50      0.24      0.31      3460\n",
      "weighted avg       0.53      0.29      0.36      3460\n",
      " samples avg       0.27      0.21      0.22      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    3.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    3.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.41209073217149766\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5357, Recall: 0.3514, F1-measure: 0.4244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.33      0.14      0.20       507\n",
      "   flashback       0.39      0.11      0.17       549\n",
      "      murder       0.63      0.53      0.57      1043\n",
      "    romantic       0.45      0.25      0.32       534\n",
      "    violence       0.55      0.49      0.52       827\n",
      "\n",
      "   micro avg       0.54      0.35      0.42      3460\n",
      "   macro avg       0.47      0.30      0.36      3460\n",
      "weighted avg       0.50      0.35      0.40      3460\n",
      " samples avg       0.30      0.26      0.26      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 5037)   (11027, 5)\n",
      "(2730, 5037)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(3,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    1.5s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    1.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    1.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    1.7s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.2909740125066573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5087, Recall: 0.1861, F1-measure: 0.2725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.40      0.04      0.08       507\n",
      "   flashback       0.25      0.03      0.05       549\n",
      "      murder       0.54      0.36      0.43      1043\n",
      "    romantic       0.46      0.11      0.18       534\n",
      "    violence       0.53      0.20      0.29       827\n",
      "\n",
      "   micro avg       0.51      0.19      0.27      3460\n",
      "   macro avg       0.44      0.15      0.21      3460\n",
      "weighted avg       0.46      0.19      0.25      3460\n",
      " samples avg       0.18      0.14      0.15      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1089s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  55 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  55 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  55 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    0.6s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.33375960286796164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3553, Recall: 0.3341, F1-measure: 0.3444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.23      0.21      0.22       507\n",
      "   flashback       0.26      0.24      0.25       549\n",
      "      murder       0.47      0.43      0.45      1043\n",
      "    romantic       0.28      0.30      0.29       534\n",
      "    violence       0.40      0.37      0.38       827\n",
      "\n",
      "   micro avg       0.36      0.33      0.34      3460\n",
      "   macro avg       0.33      0.31      0.32      3460\n",
      "weighted avg       0.36      0.33      0.34      3460\n",
      " samples avg       0.25      0.25      0.22      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0725s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  55 | elapsed:    0.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  55 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  55 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.3358370647517559\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3523, Recall: 0.3173, F1-measure: 0.3339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.23      0.20      0.21       507\n",
      "   flashback       0.22      0.21      0.22       549\n",
      "      murder       0.47      0.44      0.46      1043\n",
      "    romantic       0.30      0.27      0.29       534\n",
      "    violence       0.40      0.33      0.36       827\n",
      "\n",
      "   micro avg       0.35      0.32      0.33      3460\n",
      "   macro avg       0.32      0.29      0.31      3460\n",
      "weighted avg       0.35      0.32      0.33      3460\n",
      " samples avg       0.24      0.23      0.21      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni,bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 109114)   (11027, 5)\n",
      "(2730, 109114)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    2.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    2.7s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    3.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    3.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.40264630207628344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6305, Recall: 0.3092, F1-measure: 0.4150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.52      0.07      0.12       507\n",
      "   flashback       0.33      0.03      0.05       549\n",
      "      murder       0.66      0.54      0.59      1043\n",
      "    romantic       0.60      0.22      0.32       534\n",
      "    violence       0.64      0.41      0.50       827\n",
      "\n",
      "   micro avg       0.63      0.31      0.41      3460\n",
      "   macro avg       0.55      0.25      0.32      3460\n",
      "weighted avg       0.57      0.31      0.37      3460\n",
      " samples avg       0.30      0.24      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    8.3s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    9.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_i...e, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "          n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'clf__estimator__alpha': [3, 3.5, 2, 2.5, 1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.44404908590584974\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4866, Recall: 0.4130, F1-measure: 0.4468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.33      0.27      0.30       507\n",
      "   flashback       0.31      0.20      0.25       549\n",
      "      murder       0.60      0.56      0.58      1043\n",
      "    romantic       0.43      0.35      0.38       534\n",
      "    violence       0.55      0.50      0.52       827\n",
      "\n",
      "   micro avg       0.49      0.41      0.45      3460\n",
      "   macro avg       0.44      0.38      0.41      3460\n",
      "weighted avg       0.48      0.41      0.44      3460\n",
      " samples avg       0.33      0.32      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    7.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    8.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4461305769525208\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4951, Recall: 0.4199, F1-measure: 0.4544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.31      0.26      0.29       507\n",
      "   flashback       0.32      0.23      0.27       549\n",
      "      murder       0.60      0.59      0.59      1043\n",
      "    romantic       0.45      0.35      0.39       534\n",
      "    violence       0.59      0.47      0.52       827\n",
      "\n",
      "   micro avg       0.50      0.42      0.45      3460\n",
      "   macro avg       0.45      0.38      0.41      3460\n",
      "weighted avg       0.49      0.42      0.45      3460\n",
      " samples avg       0.34      0.32      0.31      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni,bi,tri grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 114151)   (11027, 5)\n",
      "(2730, 114151)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    3.6s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    4.3s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    4.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4046635948108246\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,1.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6317, Recall: 0.3113, F1-measure: 0.4170\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.52      0.07      0.12       507\n",
      "   flashback       0.33      0.03      0.05       549\n",
      "      murder       0.66      0.55      0.60      1043\n",
      "    romantic       0.59      0.22      0.32       534\n",
      "    violence       0.64      0.41      0.50       827\n",
      "\n",
      "   micro avg       0.63      0.31      0.42      3460\n",
      "   macro avg       0.55      0.25      0.32      3460\n",
      "weighted avg       0.57      0.31      0.37      3460\n",
      " samples avg       0.30      0.24      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    9.0s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:   10.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4429005030403062\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5128, Recall: 0.3939, F1-measure: 0.4456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.35      0.20      0.26       507\n",
      "   flashback       0.33      0.19      0.24       549\n",
      "      murder       0.60      0.56      0.58      1043\n",
      "    romantic       0.45      0.32      0.37       534\n",
      "    violence       0.57      0.48      0.52       827\n",
      "\n",
      "   micro avg       0.51      0.39      0.45      3460\n",
      "   macro avg       0.46      0.35      0.40      3460\n",
      "weighted avg       0.49      0.39      0.43      3460\n",
      " samples avg       0.33      0.30      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    7.6s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    8.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4423138333125596\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4907, Recall: 0.4179, F1-measure: 0.4514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.33      0.23      0.27       507\n",
      "   flashback       0.32      0.27      0.29       549\n",
      "      murder       0.62      0.56      0.59      1043\n",
      "    romantic       0.42      0.38      0.39       534\n",
      "    violence       0.56      0.48      0.52       827\n",
      "\n",
      "   micro avg       0.49      0.42      0.45      3460\n",
      "   macro avg       0.45      0.38      0.41      3460\n",
      "weighted avg       0.48      0.42      0.45      3460\n",
      " samples avg       0.34      0.32      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni,bi,tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 114710)   (11027, 5)\n",
      "(2730, 114710)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,4),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    4.1s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    4.7s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    5.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.40416379234010996\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,1.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6326, Recall: 0.3116, F1-measure: 0.4175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.52      0.07      0.12       507\n",
      "   flashback       0.33      0.03      0.05       549\n",
      "      murder       0.66      0.56      0.60      1043\n",
      "    romantic       0.59      0.22      0.32       534\n",
      "    violence       0.64      0.41      0.50       827\n",
      "\n",
      "   micro avg       0.63      0.31      0.42      3460\n",
      "   macro avg       0.55      0.25      0.32      3460\n",
      "weighted avg       0.57      0.31      0.37      3460\n",
      " samples avg       0.31      0.24      0.25      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    8.6s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    9.7s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4470457517563778\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4983, Recall: 0.4211, F1-measure: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.22      0.27       507\n",
      "   flashback       0.32      0.23      0.27       549\n",
      "      murder       0.60      0.58      0.59      1043\n",
      "    romantic       0.45      0.35      0.39       534\n",
      "    violence       0.56      0.51      0.54       827\n",
      "\n",
      "   micro avg       0.50      0.42      0.46      3460\n",
      "   macro avg       0.45      0.38      0.41      3460\n",
      "weighted avg       0.48      0.42      0.45      3460\n",
      " samples avg       0.34      0.32      0.31      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    8.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    8.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.44719366389960297\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4993, Recall: 0.4113, F1-measure: 0.4510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.33      0.23      0.27       507\n",
      "   flashback       0.32      0.19      0.24       549\n",
      "      murder       0.58      0.60      0.59      1043\n",
      "    romantic       0.46      0.32      0.38       534\n",
      "    violence       0.56      0.49      0.52       827\n",
      "\n",
      "   micro avg       0.50      0.41      0.45      3460\n",
      "   macro avg       0.45      0.37      0.40      3460\n",
      "weighted avg       0.48      0.41      0.44      3460\n",
      " samples avg       0.34      0.31      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 10726)   (11027, 5)\n",
      "(2730, 10726)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(3,3),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    8.2s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:    9.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.20812916540513837\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6520, Recall: 0.1370, F1-measure: 0.2264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.36      0.01      0.02       507\n",
      "   flashback       0.24      0.01      0.01       549\n",
      "      murder       0.68      0.30      0.41      1043\n",
      "    romantic       0.55      0.06      0.11       534\n",
      "    violence       0.67      0.15      0.25       827\n",
      "\n",
      "   micro avg       0.65      0.14      0.23      3460\n",
      "   macro avg       0.50      0.10      0.16      3460\n",
      "weighted avg       0.54      0.14      0.20      3460\n",
      " samples avg       0.16      0.11      0.12      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.001),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    8.4s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   10.2s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   10.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4293469804279494\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5421, Recall: 0.4090, F1-measure: 0.4662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.44      0.07      0.12       507\n",
      "   flashback       0.34      0.13      0.19       549\n",
      "      murder       0.59      0.66      0.62      1043\n",
      "    romantic       0.51      0.31      0.38       534\n",
      "    violence       0.55      0.55      0.55       827\n",
      "\n",
      "   micro avg       0.54      0.41      0.47      3460\n",
      "   macro avg       0.49      0.34      0.37      3460\n",
      "weighted avg       0.51      0.41      0.43      3460\n",
      " samples avg       0.35      0.31      0.31      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    7.5s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    9.0s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4351208283706366\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4095, Recall: 0.4506, F1-measure: 0.4291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.32      0.40      0.35       507\n",
      "   flashback       0.29      0.31      0.30       549\n",
      "      murder       0.62      0.42      0.50      1043\n",
      "    romantic       0.30      0.60      0.40       534\n",
      "    violence       0.53      0.51      0.52       827\n",
      "\n",
      "   micro avg       0.41      0.45      0.43      3460\n",
      "   macro avg       0.41      0.45      0.42      3460\n",
      "weighted avg       0.45      0.45      0.44      3460\n",
      " samples avg       0.33      0.35      0.31      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 82528)   (11027, 5)\n",
      "(2730, 82528)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(4,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   15.4s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   18.2s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   19.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.378338325107332\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5884, Recall: 0.2855, F1-measure: 0.3845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.46      0.07      0.13       507\n",
      "   flashback       0.23      0.03      0.05       549\n",
      "      murder       0.63      0.49      0.55      1043\n",
      "    romantic       0.50      0.20      0.29       534\n",
      "    violence       0.62      0.39      0.48       827\n",
      "\n",
      "   micro avg       0.59      0.29      0.38      3460\n",
      "   macro avg       0.49      0.24      0.30      3460\n",
      "weighted avg       0.52      0.29      0.35      3460\n",
      " samples avg       0.28      0.22      0.23      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   27.5s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   28.0s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.44254741962626803\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4771, Recall: 0.3945, F1-measure: 0.4319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.35      0.23      0.28       507\n",
      "   flashback       0.30      0.22      0.25       549\n",
      "      murder       0.59      0.52      0.56      1043\n",
      "    romantic       0.38      0.38      0.38       534\n",
      "    violence       0.57      0.46      0.51       827\n",
      "\n",
      "   micro avg       0.48      0.39      0.43      3460\n",
      "   macro avg       0.44      0.36      0.39      3460\n",
      "weighted avg       0.47      0.39      0.43      3460\n",
      " samples avg       0.33      0.31      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   24.6s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   24.9s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.43962189082584513\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4820, Recall: 0.3913, F1-measure: 0.4320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.35      0.30      0.33       507\n",
      "   flashback       0.29      0.24      0.26       549\n",
      "      murder       0.62      0.52      0.57      1043\n",
      "    romantic       0.42      0.36      0.39       534\n",
      "    violence       0.57      0.41      0.48       827\n",
      "\n",
      "   micro avg       0.48      0.39      0.43      3460\n",
      "   macro avg       0.45      0.37      0.40      3460\n",
      "weighted avg       0.49      0.39      0.43      3460\n",
      " samples avg       0.33      0.31      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93254)   (11027, 5)\n",
      "(2730, 93254)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(3,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   33.1s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   34.6s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.38621552617690075\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5842, Recall: 0.2968, F1-measure: 0.3936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.44      0.08      0.13       507\n",
      "   flashback       0.24      0.03      0.05       549\n",
      "      murder       0.64      0.51      0.56      1043\n",
      "    romantic       0.51      0.22      0.30       534\n",
      "    violence       0.60      0.40      0.48       827\n",
      "\n",
      "   micro avg       0.58      0.30      0.39      3460\n",
      "   macro avg       0.49      0.25      0.31      3460\n",
      "weighted avg       0.52      0.30      0.36      3460\n",
      " samples avg       0.29      0.23      0.24      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   18.5s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   22.9s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4427437289754312\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4895, Recall: 0.4043, F1-measure: 0.4429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.32      0.19      0.24       507\n",
      "   flashback       0.30      0.26      0.28       549\n",
      "      murder       0.59      0.56      0.58      1043\n",
      "    romantic       0.46      0.30      0.36       534\n",
      "    violence       0.56      0.50      0.53       827\n",
      "\n",
      "   micro avg       0.49      0.40      0.44      3460\n",
      "   macro avg       0.45      0.36      0.40      3460\n",
      "weighted avg       0.48      0.40      0.44      3460\n",
      " samples avg       0.33      0.31      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   16.5s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   19.9s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-08, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.436393896249056\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7,10**-8,10**-9],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4597, Recall: 0.4350, F1-measure: 0.4470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.34      0.23      0.28       507\n",
      "   flashback       0.26      0.24      0.25       549\n",
      "      murder       0.59      0.55      0.57      1043\n",
      "    romantic       0.41      0.44      0.42       534\n",
      "    violence       0.51      0.54      0.52       827\n",
      "\n",
      "   micro avg       0.46      0.43      0.45      3460\n",
      "   macro avg       0.42      0.40      0.41      3460\n",
      "weighted avg       0.45      0.43      0.44      3460\n",
      " samples avg       0.34      0.34      0.31      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-08,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and bi,tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93963)   (11027, 5)\n",
      "(2730, 93963)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   34.9s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   38.4s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   39.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.3674700024758224\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5976, Recall: 0.2717, F1-measure: 0.3735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.44      0.06      0.10       507\n",
      "   flashback       0.27      0.02      0.04       549\n",
      "      murder       0.64      0.48      0.55      1043\n",
      "    romantic       0.51      0.19      0.27       534\n",
      "    violence       0.63      0.36      0.46       827\n",
      "\n",
      "   micro avg       0.60      0.27      0.37      3460\n",
      "   macro avg       0.50      0.22      0.28      3460\n",
      "weighted avg       0.53      0.27      0.34      3460\n",
      " samples avg       0.27      0.21      0.22      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   27.3s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   27.9s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4419224936679708\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5652, Recall: 0.3821, F1-measure: 0.4559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.39      0.14      0.21       507\n",
      "   flashback       0.38      0.16      0.23       549\n",
      "      murder       0.63      0.57      0.60      1043\n",
      "    romantic       0.54      0.27      0.36       534\n",
      "    violence       0.60      0.50      0.55       827\n",
      "\n",
      "   micro avg       0.57      0.38      0.46      3460\n",
      "   macro avg       0.51      0.33      0.39      3460\n",
      "weighted avg       0.53      0.38      0.43      3460\n",
      " samples avg       0.34      0.29      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   24.3s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   24.9s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4379257193438696\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4948, Recall: 0.3962, F1-measure: 0.4401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.35      0.25      0.29       507\n",
      "   flashback       0.30      0.21      0.25       549\n",
      "      murder       0.61      0.51      0.56      1043\n",
      "    romantic       0.43      0.31      0.36       534\n",
      "    violence       0.56      0.51      0.54       827\n",
      "\n",
      "   micro avg       0.49      0.40      0.44      3460\n",
      "   macro avg       0.45      0.36      0.40      3460\n",
      "weighted avg       0.48      0.40      0.43      3460\n",
      " samples avg       0.32      0.31      0.29      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and uni,bi,tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93990)   (11027, 5)\n",
      "(2730, 93990)   (2730, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   36.5s remaining:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   38.1s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   39.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.25840812573469113\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6402, Recall: 0.1821, F1-measure: 0.2835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.45      0.02      0.04       507\n",
      "   flashback       0.21      0.01      0.02       549\n",
      "      murder       0.67      0.36      0.47      1043\n",
      "    romantic       0.54      0.09      0.16       534\n",
      "    violence       0.67      0.22      0.34       827\n",
      "\n",
      "   micro avg       0.64      0.18      0.28      3460\n",
      "   macro avg       0.51      0.14      0.20      3460\n",
      "weighted avg       0.55      0.18      0.26      3460\n",
      " samples avg       0.20      0.14      0.16      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.001),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   27.7s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   28.2s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.44379329982310267\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5515, Recall: 0.3777, F1-measure: 0.4484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.39      0.20      0.27       507\n",
      "   flashback       0.34      0.18      0.24       549\n",
      "      murder       0.63      0.53      0.58      1043\n",
      "    romantic       0.54      0.29      0.38       534\n",
      "    violence       0.60      0.48      0.53       827\n",
      "\n",
      "   micro avg       0.55      0.38      0.45      3460\n",
      "   macro avg       0.50      0.34      0.40      3460\n",
      "weighted avg       0.53      0.38      0.44      3460\n",
      " samples avg       0.32      0.29      0.28      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   24.9s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   25.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4426201252171625\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4857, Recall: 0.3936, F1-measure: 0.4349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cult       0.32      0.22      0.26       507\n",
      "   flashback       0.31      0.18      0.23       549\n",
      "      murder       0.59      0.56      0.57      1043\n",
      "    romantic       0.41      0.29      0.34       534\n",
      "    violence       0.53      0.51      0.52       827\n",
      "\n",
      "   micro avg       0.49      0.39      0.43      3460\n",
      "   macro avg       0.43      0.35      0.38      3460\n",
      "weighted avg       0.47      0.39      0.42      3460\n",
      " samples avg       0.33      0.31      0.30      3460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorization with word analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  1,1   |  0.364   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,1   |  0.442   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  1,1   |  0.452   |     1e-06      |\n",
      "|    MultinomialNB     |  2,2   |  0.420   |      0.1       |\n",
      "|  SGDClassifier(log)  |  2,2   |  0.386   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  2,2   |  0.424   |     1e-06      |\n",
      "|    MultinomialNB     |  3,3   |  0.272   |      0.01      |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.344   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.333   |     1e-06      |\n",
      "|    MultinomialNB     |  1,2   |  0.415   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,2   |  0.446   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  1,2   |  0.454   |     1e-06      |\n",
      "|    MultinomialNB     |  1,3   |  0.417   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,3   |  0.445   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  1,3   |  0.451   |     1e-05      |\n",
      "|    MultinomialNB     |  1,4   |  0.417   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,4   |  0.456   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  1,4   |  0.451   |     1e-06      |\n",
      "+----------------------+--------+----------+----------------+\n",
      "\n",
      "TfidfVectorization with char analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  3,3   |  0.226   |     0.001      |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.466   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.429   |     1e-05      |\n",
      "|    MultinomialNB     |  4,4   |  0.384   |      0.01      |\n",
      "|  SGDClassifier(log)  |  4,4   |  0.431   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  4,4   |  0.432   |     1e-05      |\n",
      "|    MultinomialNB     |  3,4   |  0.393   |      0.01      |\n",
      "|  SGDClassifier(log)  |  3,4   |  0.442   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  3,4   |  0.447   |     1e-08      |\n",
      "|    MultinomialNB     |  2,4   |  0.373   |      0.01      |\n",
      "|  SGDClassifier(log)  |  2,4   |  0.455   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  2,4   |  0.440   |     1e-05      |\n",
      "|    MultinomialNB     |  1,4   |  0.283   |     0.001      |\n",
      "|  SGDClassifier(log)  |  1,4   |  0.448   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  1,4   |  0.434   |     1e-06      |\n",
      "+----------------------+--------+----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "print(\"TfidfVectorization with word analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','1,1','0.364','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,1','0.442','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,1','0.452','1e-06'])\n",
    "table.add_row(['MultinomialNB','2,2','0.420','0.1'])\n",
    "table.add_row(['SGDClassifier(log)','2,2','0.386','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,2','0.424','1e-06'])\n",
    "table.add_row(['MultinomialNB','3,3','0.272','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.344','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.333','1e-06'])\n",
    "table.add_row(['MultinomialNB','1,2','0.415','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,2','0.446','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,2','0.454','1e-06'])\n",
    "table.add_row(['MultinomialNB','1,3','0.417','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,3','0.445','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,3','0.451','1e-05'])\n",
    "table.add_row(['MultinomialNB','1,4','0.417','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,4','0.456','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,4','0.451','1e-06'])\n",
    "print(table)\n",
    "print('')\n",
    "table = PrettyTable()\n",
    "print(\"TfidfVectorization with char analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','3,3','0.226','0.001'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.466','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.429','1e-05'])\n",
    "table.add_row(['MultinomialNB','4,4','0.384','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','4,4','0.431','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','4,4','0.432','1e-05'])\n",
    "table.add_row(['MultinomialNB','3,4','0.393','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','3,4','0.442','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,4','0.447','1e-08'])\n",
    "table.add_row(['MultinomialNB','2,4','0.373','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','2,4','0.455','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,4','0.440','1e-05'])\n",
    "table.add_row(['MultinomialNB','1,4','0.283','0.001'])\n",
    "table.add_row(['SGDClassifier(log)','1,4','0.448','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,4','0.434','1e-06'])\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
