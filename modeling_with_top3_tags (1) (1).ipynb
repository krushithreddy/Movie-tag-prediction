{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>MPST: A Corpus of Movie Plot Synopses with Tags</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/krushithreddy0817/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm\n",
    "\n",
    "import nltk\n",
    "from itertools import combinations\n",
    "#from toolz import compose\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import sent_tokenize\n",
    "stemmer = SnowballStemmer('english')\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,hamming_loss\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>cnt_dup</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>synopsis_count</th>\n",
       "      <th>synopsis_sent_count</th>\n",
       "      <th>CleanedSynopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "      <td>Set in Hamburg, West Germany, several criminal...</td>\n",
       "      <td>murder</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>26</td>\n",
       "      <td>set hamburg west germani sever crimin take adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$windle</td>\n",
       "      <td>A 6th grader named Griffin Bing decides to gat...</td>\n",
       "      <td>flashback</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>14</td>\n",
       "      <td>grader name griffin bing decid gather entir gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'71</td>\n",
       "      <td>Gary Hook, a new recruit to the British Army, ...</td>\n",
       "      <td>suspenseful, neo noir, murder, violence</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>gari hook new recruit british armi take leav m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'A' gai wak</td>\n",
       "      <td>Sergeant Dragon Ma (Jackie Chan) is part of th...</td>\n",
       "      <td>cult, violence</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>665</td>\n",
       "      <td>41</td>\n",
       "      <td>sergeant dragon jacki chan part hong kong mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Breaker' Morant</td>\n",
       "      <td>In Pretoria, South Africa, in 1902, Major Char...</td>\n",
       "      <td>murder, anti war, violence, flashback, tragedy...</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1694</td>\n",
       "      <td>140</td>\n",
       "      <td>pretoria south africa major charl bolton rod m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                      plot_synopsis  \\\n",
       "0                 $  Set in Hamburg, West Germany, several criminal...   \n",
       "1           $windle  A 6th grader named Griffin Bing decides to gat...   \n",
       "2               '71  Gary Hook, a new recruit to the British Army, ...   \n",
       "3       'A' gai wak  Sergeant Dragon Ma (Jackie Chan) is part of th...   \n",
       "4  'Breaker' Morant  In Pretoria, South Africa, in 1902, Major Char...   \n",
       "\n",
       "                                                tags  split synopsis_source  \\\n",
       "0                                             murder   test            imdb   \n",
       "1                                          flashback  train       wikipedia   \n",
       "2            suspenseful, neo noir, murder, violence  train       wikipedia   \n",
       "3                                     cult, violence  train       wikipedia   \n",
       "4  murder, anti war, violence, flashback, tragedy...  train       wikipedia   \n",
       "\n",
       "   cnt_dup  tag_count  synopsis_count  synopsis_sent_count  \\\n",
       "0        1          1             648                   26   \n",
       "1        1          1             353                   14   \n",
       "2        1          4             699                   39   \n",
       "3        1          2             665                   41   \n",
       "4        1          6            1694                  140   \n",
       "\n",
       "                                     CleanedSynopsis  \n",
       "0  set hamburg west germani sever crimin take adv...  \n",
       "1  grader name griffin bing decid gather entir gr...  \n",
       "2  gari hook new recruit british armi take leav m...  \n",
       "3  sergeant dragon jacki chan part hong kong mari...  \n",
       "4  pretoria south africa major charl bolton rod m...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"cleaned_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('cleaned_data.db')\n",
    "data.to_sql('cleaned_data', conn, if_exists='replace', index=False)\n",
    "train = pd.read_sql(\"Select * From cleaned_data where split = 'train' OR split='val'\",conn)\n",
    "test =  pd.read_sql(\"Select * From cleaned_data where split = 'test'\",conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              title                                      plot_synopsis  \\\n",
      "0           $windle  A 6th grader named Griffin Bing decides to gat...   \n",
      "1               '71  Gary Hook, a new recruit to the British Army, ...   \n",
      "2       'A' gai wak  Sergeant Dragon Ma (Jackie Chan) is part of th...   \n",
      "3  'Breaker' Morant  In Pretoria, South Africa, in 1902, Major Char...   \n",
      "4           'C'-Man  Customs Investigator Cliff Holden (Dean Jagger...   \n",
      "\n",
      "                                                tags  split synopsis_source  \\\n",
      "0                                          flashback  train       wikipedia   \n",
      "1            suspenseful, neo noir, murder, violence  train       wikipedia   \n",
      "2                                     cult, violence  train       wikipedia   \n",
      "3  murder, anti war, violence, flashback, tragedy...  train       wikipedia   \n",
      "4                                             murder  train            imdb   \n",
      "\n",
      "   cnt_dup  tag_count  synopsis_count  synopsis_sent_count  \\\n",
      "0        1          1             353                   14   \n",
      "1        1          4             699                   39   \n",
      "2        1          2             665                   41   \n",
      "3        1          6            1694                  140   \n",
      "4        1          1            1421                  102   \n",
      "\n",
      "                                     CleanedSynopsis  \n",
      "0  grader name griffin bing decid gather entir gr...  \n",
      "1  gari hook new recruit british armi take leav m...  \n",
      "2  sergeant dragon jacki chan part hong kong mari...  \n",
      "3  pretoria south africa major charl bolton rod m...  \n",
      "4  custom investig cliff holden dean jagger retur...  \n",
      "(11027, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             title  \\\n",
      "0                                                $   \n",
      "1                            'Crocodile' Dundee II   \n",
      "2                      'Hukkunud Alpinisti' hotell   \n",
      "3  'Northwest Passage' (Book I -- Rogers' Rangers)   \n",
      "4                             (500) Days of Summer   \n",
      "\n",
      "                                       plot_synopsis  \\\n",
      "0  Set in Hamburg, West Germany, several criminal...   \n",
      "1  A year has passed since the events of Crocodil...   \n",
      "2  Inspector Glebsky arrives at the hotel \"Dead M...   \n",
      "3  === Book 1 ===\\nLangdon Towne is a young Congr...   \n",
      "4  (500) Days of Summer is presented in a non-chr...   \n",
      "\n",
      "                                                tags split synopsis_source  \\\n",
      "0                                             murder  test            imdb   \n",
      "1                                             murder  test       wikipedia   \n",
      "2                             cult, neo noir, murder  test       wikipedia   \n",
      "3           tragedy, revenge, cult, murder, violence  test       wikipedia   \n",
      "4  boring, depressing, stupid, cult, cute, magica...  test            imdb   \n",
      "\n",
      "   cnt_dup  tag_count  synopsis_count  synopsis_sent_count  \\\n",
      "0        1          1             648                   26   \n",
      "1        1          1             550                   25   \n",
      "2        1          3             260                   23   \n",
      "3        1          5            1269                   52   \n",
      "4        1         13            1680                  124   \n",
      "\n",
      "                                     CleanedSynopsis  \n",
      "0  set hamburg west germani sever crimin take adv...  \n",
      "1  year pass sinc event crocodil dunde mick dunde...  \n",
      "2  inspector glebski arriv hotel dead mountain an...  \n",
      "3  book langdon town young congregationalist resi...  \n",
      "4  day summer present non chronolog format scene ...  \n",
      "(2730, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test.head())\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag vectorizaton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flashback', 'murder', 'violence']\n"
     ]
    }
   ],
   "source": [
    "tag_vect = CountVectorizer(max_features=3,tokenizer = lambda x: str(x).split(\", \"))\n",
    "y_train = tag_vect.fit_transform(train['tags'])\n",
    "y_test = tag_vect.transform(test['tags'])\n",
    "print(tag_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = tag_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and uni grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize=CountVectorizer()\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 78666)   (11027, 3)\n",
      "(2730, 78666)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:    3.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:    4.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5320886096806409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5143, Recall: 0.5577, F1-measure: 0.5351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.27      0.25      0.26       549\n",
      "      murder       0.60      0.66      0.63      1043\n",
      "    violence       0.55      0.63      0.58       827\n",
      "\n",
      "   micro avg       0.51      0.56      0.54      2419\n",
      "   macro avg       0.47      0.51      0.49      2419\n",
      "weighted avg       0.51      0.56      0.53      2419\n",
      " samples avg       0.31      0.33      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    4.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5299295701288367"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6351, Recall: 0.4188, F1-measure: 0.5047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.39      0.12      0.18       549\n",
      "      murder       0.68      0.55      0.61      1043\n",
      "    violence       0.64      0.45      0.53       827\n",
      "\n",
      "   micro avg       0.64      0.42      0.50      2419\n",
      "   macro avg       0.57      0.37      0.44      2419\n",
      "weighted avg       0.60      0.42      0.48      2419\n",
      " samples avg       0.27      0.24      0.24      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    3.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    3.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5297687098911606\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6327, Recall: 0.4237, F1-measure: 0.5076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.37      0.11      0.17       549\n",
      "      murder       0.70      0.53      0.61      1043\n",
      "    violence       0.62      0.49      0.55       827\n",
      "\n",
      "   micro avg       0.63      0.42      0.51      2419\n",
      "   macro avg       0.56      0.38      0.44      2419\n",
      "weighted avg       0.60      0.42      0.49      2419\n",
      " samples avg       0.27      0.24      0.24      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and bi grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 89722)   (11027, 3)\n",
      "(2730, 89722)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(2,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:    2.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:    2.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=2, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5573266063061614\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,2.5,2,1.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5723, Recall: 0.5250, F1-measure: 0.5476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.36      0.16      0.22       549\n",
      "      murder       0.64      0.67      0.65      1043\n",
      "    violence       0.55      0.59      0.57       827\n",
      "\n",
      "   micro avg       0.57      0.53      0.55      2419\n",
      "   macro avg       0.52      0.47      0.48      2419\n",
      "weighted avg       0.54      0.53      0.53      2419\n",
      " samples avg       0.30      0.30      0.29      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=2),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    1.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    1.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.48161720542090897\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6,10**-7,10**-8],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5409, Recall: 0.3907, F1-measure: 0.4537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.31      0.17      0.22       549\n",
      "      murder       0.62      0.49      0.54      1043\n",
      "    violence       0.55      0.42      0.47       827\n",
      "\n",
      "   micro avg       0.54      0.39      0.45      2419\n",
      "   macro avg       0.49      0.36      0.41      2419\n",
      "weighted avg       0.52      0.39      0.45      2419\n",
      " samples avg       0.25      0.22      0.22      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    2.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    2.3s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.48235447208338217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5190, Recall: 0.4456, F1-measure: 0.4795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.29      0.18      0.22       549\n",
      "      murder       0.59      0.55      0.57      1043\n",
      "    violence       0.53      0.49      0.51       827\n",
      "\n",
      "   micro avg       0.52      0.45      0.48      2419\n",
      "   macro avg       0.47      0.41      0.43      2419\n",
      "weighted avg       0.50      0.45      0.47      2419\n",
      " samples avg       0.27      0.25      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and tri grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 5037)   (11027, 3)\n",
      "(2730, 5037)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(3,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1396s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  40 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  40 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    0.6s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4046109161812072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4980, Recall: 0.3129, F1-measure: 0.3844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.31      0.17      0.22       549\n",
      "      murder       0.53      0.49      0.51      1043\n",
      "    violence       0.57      0.19      0.29       827\n",
      "\n",
      "   micro avg       0.50      0.31      0.38      2419\n",
      "   macro avg       0.47      0.28      0.34      2419\n",
      "weighted avg       0.50      0.31      0.37      2419\n",
      " samples avg       0.20      0.18      0.18      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0693s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  40 | elapsed:    0.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  40 | elapsed:    0.2s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.3809500587263854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  40 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4137, Recall: 0.3439, F1-measure: 0.3756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.26      0.21      0.23       549\n",
      "      murder       0.48      0.40      0.44      1043\n",
      "    violence       0.42      0.36      0.39       827\n",
      "\n",
      "   micro avg       0.41      0.34      0.38      2419\n",
      "   macro avg       0.39      0.32      0.35      2419\n",
      "weighted avg       0.41      0.34      0.38      2419\n",
      " samples avg       0.21      0.20      0.19      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0490s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  40 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  40 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  40 | elapsed:    0.1s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.3839222235151611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3991, Recall: 0.3712, F1-measure: 0.3847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.26      0.21      0.24       549\n",
      "      murder       0.47      0.45      0.46      1043\n",
      "    violence       0.39      0.38      0.38       827\n",
      "\n",
      "   micro avg       0.40      0.37      0.38      2419\n",
      "   macro avg       0.37      0.35      0.36      2419\n",
      "weighted avg       0.40      0.37      0.38      2419\n",
      " samples avg       0.22      0.21      0.20      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and uni,bi grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 109114)   (11027, 3)\n",
      "(2730, 109114)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(1,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    4.4s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    4.7s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5582516700684903\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5495, Recall: 0.5717, F1-measure: 0.5604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.31      0.26      0.28       549\n",
      "      murder       0.65      0.68      0.66      1043\n",
      "    violence       0.56      0.64      0.60       827\n",
      "\n",
      "   micro avg       0.55      0.57      0.56      2419\n",
      "   macro avg       0.50      0.53      0.51      2419\n",
      "weighted avg       0.54      0.57      0.55      2419\n",
      " samples avg       0.31      0.33      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    4.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    5.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5242579145967816\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6507, Recall: 0.4212, F1-measure: 0.5114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.41      0.08      0.13       549\n",
      "      murder       0.67      0.59      0.63      1043\n",
      "    violence       0.66      0.43      0.52       827\n",
      "\n",
      "   micro avg       0.65      0.42      0.51      2419\n",
      "   macro avg       0.58      0.37      0.43      2419\n",
      "weighted avg       0.61      0.42      0.48      2419\n",
      " samples avg       0.27      0.24      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    3.4s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    4.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5292699952814558\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6192, Recall: 0.4274, F1-measure: 0.5057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.35      0.16      0.22       549\n",
      "      murder       0.67      0.62      0.64      1043\n",
      "    violence       0.67      0.37      0.47       827\n",
      "\n",
      "   micro avg       0.62      0.43      0.51      2419\n",
      "   macro avg       0.56      0.38      0.45      2419\n",
      "weighted avg       0.60      0.43      0.49      2419\n",
      " samples avg       0.28      0.25      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with words and uni,bi,tri grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 114151)   (11027, 3)\n",
      "(2730, 114151)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(1,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    4.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    5.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5577807704762309\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5517, Recall: 0.5692, F1-measure: 0.5603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.32      0.27      0.29       549\n",
      "      murder       0.64      0.67      0.66      1043\n",
      "    violence       0.56      0.63      0.60       827\n",
      "\n",
      "   micro avg       0.55      0.57      0.56      2419\n",
      "   macro avg       0.51      0.53      0.52      2419\n",
      "weighted avg       0.54      0.57      0.55      2419\n",
      " samples avg       0.31      0.33      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    5.4s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    6.4s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5195591656876584\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5530, Recall: 0.4510, F1-measure: 0.4968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.30      0.16      0.21       549\n",
      "      murder       0.62      0.56      0.59      1043\n",
      "    violence       0.56      0.51      0.53       827\n",
      "\n",
      "   micro avg       0.55      0.45      0.50      2419\n",
      "   macro avg       0.50      0.41      0.44      2419\n",
      "weighted avg       0.53      0.45      0.48      2419\n",
      " samples avg       0.28      0.26      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.01,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    3.3s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    4.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.519281737313241\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6505, Recall: 0.3886, F1-measure: 0.4865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.35      0.07      0.12       549\n",
      "      murder       0.70      0.52      0.60      1043\n",
      "    violence       0.64      0.43      0.52       827\n",
      "\n",
      "   micro avg       0.65      0.39      0.49      2419\n",
      "   macro avg       0.57      0.34      0.41      2419\n",
      "weighted avg       0.60      0.39      0.46      2419\n",
      " samples avg       0.26      0.22      0.23      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and tri grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 10726)   (11027, 3)\n",
      "(2730, 10726)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(3,3),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    9.8s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   10.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=2.5, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4907140280954945\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4919, Recall: 0.5891, F1-measure: 0.5361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.26      0.35      0.30       549\n",
      "      murder       0.61      0.65      0.63      1043\n",
      "    violence       0.53      0.67      0.59       827\n",
      "\n",
      "   micro avg       0.49      0.59      0.54      2419\n",
      "   macro avg       0.47      0.56      0.51      2419\n",
      "weighted avg       0.50      0.59      0.54      2419\n",
      " samples avg       0.30      0.34      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=2.5),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    9.9s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   11.7s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=2.5, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4996760208324402\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6706, Recall: 0.3258, F1-measure: 0.4385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.20      0.01      0.01       549\n",
      "      murder       0.70      0.47      0.56      1043\n",
      "    violence       0.65      0.36      0.46       827\n",
      "\n",
      "   micro avg       0.67      0.33      0.44      2419\n",
      "   macro avg       0.51      0.28      0.34      2419\n",
      "weighted avg       0.57      0.33      0.40      2419\n",
      " samples avg       0.21      0.19      0.19      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=2.5,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   10.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   10.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5025470908756237\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4860, Recall: 0.5006, F1-measure: 0.4932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.27      0.23      0.25       549\n",
      "      murder       0.63      0.49      0.55      1043\n",
      "    violence       0.48      0.70      0.57       827\n",
      "\n",
      "   micro avg       0.49      0.50      0.49      2419\n",
      "   macro avg       0.46      0.47      0.45      2419\n",
      "weighted avg       0.49      0.50      0.49      2419\n",
      " samples avg       0.30      0.29      0.28      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.0001,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 82528)   (11027, 3)\n",
      "(2730, 82528)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(4,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   16.2s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   18.5s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   19.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=2, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5457335895170159\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5200, Recall: 0.5763, F1-measure: 0.5467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.29      0.30      0.30       549\n",
      "      murder       0.62      0.66      0.64      1043\n",
      "    violence       0.55      0.66      0.60       827\n",
      "\n",
      "   micro avg       0.52      0.58      0.55      2419\n",
      "   macro avg       0.48      0.54      0.51      2419\n",
      "weighted avg       0.52      0.58      0.54      2419\n",
      " samples avg       0.30      0.33      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=2),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   19.2s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   23.4s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5228850110818296\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5449, Recall: 0.5345, F1-measure: 0.5396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.34      0.17      0.23       549\n",
      "      murder       0.60      0.65      0.62      1043\n",
      "    violence       0.54      0.63      0.58       827\n",
      "\n",
      "   micro avg       0.54      0.53      0.54      2419\n",
      "   macro avg       0.49      0.48      0.48      2419\n",
      "weighted avg       0.52      0.53      0.52      2419\n",
      " samples avg       0.32      0.31      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=0.1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   13.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   16.8s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   17.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.520264835269807\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4621, Recall: 0.4944, F1-measure: 0.4777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.26      0.42      0.32       549\n",
      "      murder       0.56      0.60      0.58      1043\n",
      "    violence       0.56      0.41      0.47       827\n",
      "\n",
      "   micro avg       0.46      0.49      0.48      2419\n",
      "   macro avg       0.46      0.48      0.46      2419\n",
      "weighted avg       0.49      0.49      0.49      2419\n",
      " samples avg       0.28      0.29      0.27      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.01,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and three,four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93254)   (11027, 3)\n",
      "(2730, 93254)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(3,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   30.0s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   31.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   33.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=2, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5453978788963134\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5137, Recall: 0.5750, F1-measure: 0.5426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.28      0.31      0.30       549\n",
      "      murder       0.62      0.65      0.64      1043\n",
      "    violence       0.54      0.66      0.59       827\n",
      "\n",
      "   micro avg       0.51      0.58      0.54      2419\n",
      "   macro avg       0.48      0.54      0.51      2419\n",
      "weighted avg       0.52      0.58      0.54      2419\n",
      " samples avg       0.30      0.33      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=2),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   31.4s remaining:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   38.3s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   38.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   38.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5168122291715993\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6302, Recall: 0.4452, F1-measure: 0.5218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.42      0.03      0.05       549\n",
      "      murder       0.67      0.57      0.62      1043\n",
      "    violence       0.59      0.56      0.57       827\n",
      "\n",
      "   micro avg       0.63      0.45      0.52      2419\n",
      "   macro avg       0.56      0.39      0.42      2419\n",
      "weighted avg       0.59      0.45      0.48      2419\n",
      " samples avg       0.28      0.26      0.26      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   22.4s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   27.5s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   27.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5235888192652535\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6157, Recall: 0.4357, F1-measure: 0.5103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.36      0.05      0.09       549\n",
      "      murder       0.67      0.55      0.61      1043\n",
      "    violence       0.58      0.54      0.56       827\n",
      "\n",
      "   micro avg       0.62      0.44      0.51      2419\n",
      "   macro avg       0.54      0.38      0.42      2419\n",
      "weighted avg       0.57      0.44      0.47      2419\n",
      " samples avg       0.28      0.26      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and bi,tri,four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93963)   (11027, 3)\n",
      "(2730, 93963)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   31.3s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   33.9s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5452721797775765\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5034, Recall: 0.5862, F1-measure: 0.5416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.28      0.35      0.31       549\n",
      "      murder       0.62      0.65      0.63      1043\n",
      "    violence       0.53      0.66      0.59       827\n",
      "\n",
      "   micro avg       0.50      0.59      0.54      2419\n",
      "   macro avg       0.48      0.55      0.51      2419\n",
      "weighted avg       0.51      0.59      0.55      2419\n",
      " samples avg       0.31      0.34      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   34.0s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   41.4s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   41.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   41.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5017684277401824\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6368, Recall: 0.3646, F1-measure: 0.4637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.34      0.05      0.08       549\n",
      "      murder       0.64      0.62      0.63      1043\n",
      "    violence       0.70      0.25      0.37       827\n",
      "\n",
      "   micro avg       0.64      0.36      0.46      2419\n",
      "   macro avg       0.56      0.31      0.36      2419\n",
      "weighted avg       0.59      0.36      0.42      2419\n",
      " samples avg       0.26      0.21      0.22      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   24.3s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   30.2s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=2.5, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.518232839284313\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6955, Recall: 0.3154, F1-measure: 0.4340\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.44      0.01      0.01       549\n",
      "      murder       0.69      0.53      0.60      1043\n",
      "    violence       0.71      0.25      0.37       827\n",
      "\n",
      "   micro avg       0.70      0.32      0.43      2419\n",
      "   macro avg       0.62      0.26      0.33      2419\n",
      "weighted avg       0.64      0.32      0.39      2419\n",
      " samples avg       0.23      0.19      0.20      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=2.5,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizing with chars and one,bi,tri,four grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93990)   (11027, 3)\n",
      "(2730, 93990)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=CountVectorizer(ngram_range=(1,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   30.7s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   33.5s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   35.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.544813995058867\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5030, Recall: 0.5858, F1-measure: 0.5413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.28      0.35      0.31       549\n",
      "      murder       0.62      0.65      0.63      1043\n",
      "    violence       0.53      0.66      0.59       827\n",
      "\n",
      "   micro avg       0.50      0.59      0.54      2419\n",
      "   macro avg       0.48      0.55      0.51      2419\n",
      "weighted avg       0.51      0.59      0.55      2419\n",
      " samples avg       0.30      0.34      0.30      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   33.9s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   41.7s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   42.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   42.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4870044554276253\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3853, Recall: 0.7627, F1-measure: 0.5119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.24      0.60      0.35       549\n",
      "      murder       0.40      0.99      0.57      1043\n",
      "    violence       0.56      0.59      0.57       827\n",
      "\n",
      "   micro avg       0.39      0.76      0.51      2419\n",
      "   macro avg       0.40      0.72      0.50      2419\n",
      "weighted avg       0.42      0.76      0.52      2419\n",
      " samples avg       0.35      0.45      0.37      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   24.4s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   30.1s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5068243651831236\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5086, Recall: 0.5713, F1-measure: 0.5382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.29      0.08      0.13       549\n",
      "      murder       0.49      0.91      0.64      1043\n",
      "    violence       0.60      0.48      0.53       827\n",
      "\n",
      "   micro avg       0.51      0.57      0.54      2419\n",
      "   macro avg       0.46      0.49      0.43      2419\n",
      "weighted avg       0.49      0.57      0.49      2419\n",
      " samples avg       0.36      0.34      0.33      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=0.001,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorization with word analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  1,1   |  0.535   |       1        |\n",
      "|  SGDClassifier(log)  |  1,1   |  0.504   |      0.1       |\n",
      "| SGDClassifier(hinge) |  1,1   |  0.507   |      0.1       |\n",
      "|    MultinomialNB     |  2,2   |  0.547   |       2        |\n",
      "|  SGDClassifier(log)  |  2,2   |  0.453   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  2,2   |  0.479   |     1e-05      |\n",
      "|    MultinomialNB     |  3,3   |  0.384   |       1        |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.375   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.384   |     1e-05      |\n",
      "|    MultinomialNB     |  1,2   |  0.560   |       1        |\n",
      "|  SGDClassifier(log)  |  1,2   |  0.511   |      0.1       |\n",
      "| SGDClassifier(hinge) |  1,2   |  0.505   |      0.1       |\n",
      "|    MultinomialNB     |  1,3   |  0.560   |       1        |\n",
      "|  SGDClassifier(log)  |  1,3   |  0.496   |      0.01      |\n",
      "| SGDClassifier(hinge) |  1,3   |  0.486   |      0.1       |\n",
      "+----------------------+--------+----------+----------------+\n",
      "\n",
      "CountVectorization with char analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  3,3   |  0.536   |      2.5       |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.438   |      2.5       |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.493   |     0.0001     |\n",
      "|    MultinomialNB     |  4,4   |  0.546   |       2        |\n",
      "|  SGDClassifier(log)  |  4,4   |  0.539   |      0.1       |\n",
      "| SGDClassifier(hinge) |  4,4   |  0.477   |      0.1       |\n",
      "|    MultinomialNB     |  3,4   |  0.542   |       2        |\n",
      "|  SGDClassifier(log)  |  3,4   |  0.521   |       1        |\n",
      "| SGDClassifier(hinge) |  3,4   |  0.510   |       1        |\n",
      "|    MultinomialNB     |  2,4   |  0.541   |       1        |\n",
      "|  SGDClassifier(log)  |  2,4   |  0.463   |       1        |\n",
      "| SGDClassifier(hinge) |  2,4   |  0.434   |      2.5       |\n",
      "|    MultinomialNB     |  1,4   |  0.541   |       1        |\n",
      "|  SGDClassifier(log)  |  1,4   |  0.511   |       1        |\n",
      "| SGDClassifier(hinge) |  1,4   |  0.538   |     0.001      |\n",
      "+----------------------+--------+----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "print(\"CountVectorization with word analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','1,1','0.535','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,1','0.504','0.1'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,1','0.507','0.1'])\n",
    "table.add_row(['MultinomialNB','2,2','0.547','2'])\n",
    "table.add_row(['SGDClassifier(log)','2,2','0.453','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,2','0.479','1e-05'])\n",
    "table.add_row(['MultinomialNB','3,3','0.384','1'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.375','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.384','1e-05'])\n",
    "table.add_row(['MultinomialNB','1,2','0.560','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,2','0.511','0.1'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,2','0.505','0.1'])\n",
    "table.add_row(['MultinomialNB','1,3','0.560','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,3','0.496','0.01'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,3','0.486','0.1'])\n",
    "print(table)\n",
    "print(\"\")\n",
    "table = PrettyTable()\n",
    "print(\"CountVectorization with char analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','3,3','0.536','2.5'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.438','2.5'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.493','0.0001'])\n",
    "table.add_row(['MultinomialNB','4,4','0.546','2'])\n",
    "table.add_row(['SGDClassifier(log)','4,4','0.539','0.1'])\n",
    "table.add_row(['SGDClassifier(hinge)','4,4','0.477','0.1'])\n",
    "table.add_row(['MultinomialNB','3,4','0.542','2'])\n",
    "table.add_row(['SGDClassifier(log)','3,4','0.521','1'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,4','0.510','1'])\n",
    "table.add_row(['MultinomialNB','2,4','0.541','1'])\n",
    "table.add_row(['SGDClassifier(log)','2,4','0.463','1'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,4','0.434','2.5'])\n",
    "table.add_row(['MultinomialNB','1,4','0.541','1'])\n",
    "table.add_row(['SGDClassifier(log)','1,4','0.511','1'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,4','0.538','0.001'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 78666)   (11027, 3)\n",
      "(2730, 78666)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer()\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:    3.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:    3.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4364152630710981\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5526, Recall: 0.3344, F1-measure: 0.4167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.23      0.05      0.08       549\n",
      "      murder       0.58      0.47      0.52      1043\n",
      "    violence       0.58      0.36      0.44       827\n",
      "\n",
      "   micro avg       0.55      0.33      0.42      2419\n",
      "   macro avg       0.46      0.29      0.35      2419\n",
      "weighted avg       0.50      0.33      0.39      2419\n",
      " samples avg       0.23      0.20      0.20      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    3.3s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    3.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4892576007667873"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5749, Recall: 0.4713, F1-measure: 0.5179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.33      0.15      0.21       549\n",
      "      murder       0.62      0.60      0.61      1043\n",
      "    violence       0.59      0.52      0.55       827\n",
      "\n",
      "   micro avg       0.57      0.47      0.52      2419\n",
      "   macro avg       0.52      0.42      0.46      2419\n",
      "weighted avg       0.55      0.47      0.50      2419\n",
      " samples avg       0.29      0.27      0.27      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    3.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    3.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.489679677184047\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,2,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5173, Recall: 0.4812, F1-measure: 0.4986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.29      0.25      0.27       549\n",
      "      murder       0.59      0.59      0.59      1043\n",
      "    violence       0.56      0.50      0.53       827\n",
      "\n",
      "   micro avg       0.52      0.48      0.50      2419\n",
      "   macro avg       0.48      0.45      0.46      2419\n",
      "weighted avg       0.51      0.48      0.50      2419\n",
      " samples avg       0.29      0.28      0.27      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 89722)   (11027, 3)\n",
      "(2730, 89722)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(2,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    0.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    0.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    0.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.5055246557637904\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6451, Recall: 0.3952, F1-measure: 0.4901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.35      0.02      0.04       549\n",
      "      murder       0.67      0.56      0.61      1043\n",
      "    violence       0.63      0.43      0.51       827\n",
      "\n",
      "   micro avg       0.65      0.40      0.49      2419\n",
      "   macro avg       0.55      0.34      0.39      2419\n",
      "weighted avg       0.58      0.40      0.45      2419\n",
      " samples avg       0.26      0.22      0.23      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.1),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    1.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    2.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.46025958215263174\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6127, Recall: 0.3721, F1-measure: 0.4630\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.40      0.08      0.13       549\n",
      "      murder       0.65      0.49      0.56      1043\n",
      "    violence       0.60      0.41      0.49       827\n",
      "\n",
      "   micro avg       0.61      0.37      0.46      2419\n",
      "   macro avg       0.55      0.33      0.39      2419\n",
      "weighted avg       0.58      0.37      0.44      2419\n",
      " samples avg       0.25      0.21      0.21      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    1.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    1.8s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4660066000980762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5687, Recall: 0.4088, F1-measure: 0.4757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.36      0.15      0.21       549\n",
      "      murder       0.62      0.54      0.58      1043\n",
      "    violence       0.57      0.41      0.48       827\n",
      "\n",
      "   micro avg       0.57      0.41      0.48      2419\n",
      "   macro avg       0.52      0.37      0.42      2419\n",
      "weighted avg       0.54      0.41      0.46      2419\n",
      " samples avg       0.26      0.23      0.23      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 5037)   (11027, 3)\n",
      "(2730, 5037)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(3,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1337s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  25 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  25 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    0.3s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.34812966571443943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5199, Recall: 0.2323, F1-measure: 0.3211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.25      0.03      0.05       549\n",
      "      murder       0.54      0.36      0.43      1043\n",
      "    violence       0.53      0.20      0.29       827\n",
      "\n",
      "   micro avg       0.52      0.23      0.32      2419\n",
      "   macro avg       0.44      0.20      0.26      2419\n",
      "weighted avg       0.47      0.23      0.30      2419\n",
      " samples avg       0.16      0.13      0.14      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0706s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  55 | elapsed:    0.2s remaining:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.3792980337124993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 out of  55 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  55 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3870, Recall: 0.3675, F1-measure: 0.3770\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.23      0.21      0.22       549\n",
      "      murder       0.45      0.43      0.44      1043\n",
      "    violence       0.41      0.39      0.40       827\n",
      "\n",
      "   micro avg       0.39      0.37      0.38      2419\n",
      "   macro avg       0.36      0.35      0.35      2419\n",
      "weighted avg       0.39      0.37      0.38      2419\n",
      " samples avg       0.22      0.21      0.20      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0475s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  55 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  55 | elapsed:    0.2s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.3786773413863728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3886, Recall: 0.3382, F1-measure: 0.3616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.26      0.25      0.25       549\n",
      "      murder       0.46      0.38      0.42      1043\n",
      "    violence       0.39      0.34      0.37       827\n",
      "\n",
      "   micro avg       0.39      0.34      0.36      2419\n",
      "   macro avg       0.37      0.32      0.35      2419\n",
      "weighted avg       0.39      0.34      0.36      2419\n",
      " samples avg       0.21      0.19      0.19      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni,bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 109114)   (11027, 3)\n",
      "(2730, 109114)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,2),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    1.2s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    1.4s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    1.8s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    2.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.47334183970721905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6404, Recall: 0.3799, F1-measure: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.33      0.03      0.05       549\n",
      "      murder       0.66      0.54      0.59      1043\n",
      "    violence       0.64      0.41      0.50       827\n",
      "\n",
      "   micro avg       0.64      0.38      0.48      2419\n",
      "   macro avg       0.54      0.33      0.38      2419\n",
      "weighted avg       0.58      0.38      0.44      2419\n",
      " samples avg       0.26      0.22      0.23      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    5.4s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_i...e, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "          n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'clf__estimator__alpha': [3, 3.5, 2, 2.5, 1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.49637189894788586\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5952, Recall: 0.4266, F1-measure: 0.4970\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.34      0.13      0.19       549\n",
      "      murder       0.64      0.56      0.60      1043\n",
      "    violence       0.62      0.45      0.52       827\n",
      "\n",
      "   micro avg       0.60      0.43      0.50      2419\n",
      "   macro avg       0.53      0.38      0.44      2419\n",
      "weighted avg       0.56      0.43      0.48      2419\n",
      " samples avg       0.28      0.25      0.24      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    4.7s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.49755181673777343\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5187, Recall: 0.4580, F1-measure: 0.4865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.30      0.25      0.27       549\n",
      "      murder       0.60      0.54      0.57      1043\n",
      "    violence       0.55      0.49      0.52       827\n",
      "\n",
      "   micro avg       0.52      0.46      0.49      2419\n",
      "   macro avg       0.48      0.43      0.45      2419\n",
      "weighted avg       0.52      0.46      0.49      2419\n",
      " samples avg       0.28      0.27      0.26      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni,bi,tri grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 114151)   (11027, 3)\n",
      "(2730, 114151)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,3),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    2.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    2.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    3.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4744861067474211\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,1.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6422, Recall: 0.3836, F1-measure: 0.4803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.33      0.03      0.05       549\n",
      "      murder       0.66      0.55      0.60      1043\n",
      "    violence       0.64      0.41      0.50       827\n",
      "\n",
      "   micro avg       0.64      0.38      0.48      2419\n",
      "   macro avg       0.54      0.33      0.38      2419\n",
      "weighted avg       0.58      0.38      0.44      2419\n",
      " samples avg       0.26      0.22      0.23      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    5.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    6.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5006802661353171\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5995, Recall: 0.4295, F1-measure: 0.5005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.34      0.12      0.17       549\n",
      "      murder       0.65      0.55      0.60      1043\n",
      "    violence       0.60      0.49      0.54       827\n",
      "\n",
      "   micro avg       0.60      0.43      0.50      2419\n",
      "   macro avg       0.53      0.38      0.44      2419\n",
      "weighted avg       0.56      0.43      0.48      2419\n",
      " samples avg       0.28      0.25      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    5.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4985304088558513\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5304, Recall: 0.4795, F1-measure: 0.5037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.33      0.28      0.30       549\n",
      "      murder       0.60      0.59      0.60      1043\n",
      "    violence       0.56      0.48      0.51       827\n",
      "\n",
      "   micro avg       0.53      0.48      0.50      2419\n",
      "   macro avg       0.50      0.45      0.47      2419\n",
      "weighted avg       0.53      0.48      0.50      2419\n",
      " samples avg       0.29      0.28      0.27      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with words and uni,bi,tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 114710)   (11027, 3)\n",
      "(2730, 114710)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,4),min_df=0.0005)\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    3.5s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    3.8s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    4.4s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.47423785493452547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,1.5,1,10**-1, 10**-2, 10**-3, 10**-4],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6431, Recall: 0.3836, F1-measure: 0.4806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.33      0.03      0.05       549\n",
      "      murder       0.66      0.56      0.60      1043\n",
      "    violence       0.64      0.41      0.50       827\n",
      "\n",
      "   micro avg       0.64      0.38      0.48      2419\n",
      "   macro avg       0.54      0.33      0.38      2419\n",
      "weighted avg       0.58      0.38      0.44      2419\n",
      " samples avg       0.26      0.22      0.23      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    5.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5052271685141727\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5526, Recall: 0.4585, F1-measure: 0.5011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.32      0.21      0.25       549\n",
      "      murder       0.63      0.58      0.60      1043\n",
      "    violence       0.57      0.47      0.52       827\n",
      "\n",
      "   micro avg       0.55      0.46      0.50      2419\n",
      "   macro avg       0.51      0.42      0.46      2419\n",
      "weighted avg       0.54      0.46      0.49      2419\n",
      " samples avg       0.29      0.26      0.26      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  55 | elapsed:    4.7s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    5.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5068177925053681\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge'))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2,10**-3, 10**-4,10**-5,10**-6],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5095, Recall: 0.4981, F1-measure: 0.5038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.32      0.25      0.28       549\n",
      "      murder       0.58      0.58      0.58      1043\n",
      "    violence       0.52      0.56      0.54       827\n",
      "\n",
      "   micro avg       0.51      0.50      0.50      2419\n",
      "   macro avg       0.47      0.46      0.47      2419\n",
      "weighted avg       0.50      0.50      0.50      2419\n",
      " samples avg       0.29      0.28      0.27      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-06,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 10726)   (11027, 3)\n",
      "(2730, 10726)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(3,3),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    5.2s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:    6.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.0001, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.26614803669886655\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6591, Recall: 0.1807, F1-measure: 0.2836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.26      0.01      0.02       549\n",
      "      murder       0.68      0.30      0.41      1043\n",
      "    violence       0.65      0.15      0.24       827\n",
      "\n",
      "   micro avg       0.66      0.18      0.28      2419\n",
      "   macro avg       0.53      0.15      0.22      2419\n",
      "weighted avg       0.58      0.18      0.26      2419\n",
      " samples avg       0.14      0.11      0.12      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.0001),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    5.4s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    6.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.49143601615576715\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5148, Recall: 0.5684, F1-measure: 0.5403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.33      0.21      0.26       549\n",
      "      murder       0.55      0.73      0.63      1043\n",
      "    violence       0.53      0.60      0.56       827\n",
      "\n",
      "   micro avg       0.51      0.57      0.54      2419\n",
      "   macro avg       0.47      0.51      0.48      2419\n",
      "weighted avg       0.49      0.57      0.52      2419\n",
      " samples avg       0.32      0.33      0.31      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:    4.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:    5.8s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.49663593910050385\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5110, Recall: 0.4986, F1-measure: 0.5047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.32      0.20      0.25       549\n",
      "      murder       0.60      0.55      0.57      1043\n",
      "    violence       0.49      0.63      0.55       827\n",
      "\n",
      "   micro avg       0.51      0.50      0.50      2419\n",
      "   macro avg       0.47      0.46      0.46      2419\n",
      "weighted avg       0.50      0.50      0.49      2419\n",
      " samples avg       0.30      0.29      0.27      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 82528)   (11027, 3)\n",
      "(2730, 82528)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(4,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   10.1s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   11.8s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4420720269807661\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6094, Recall: 0.3489, F1-measure: 0.4437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.23      0.03      0.05       549\n",
      "      murder       0.63      0.49      0.55      1043\n",
      "    violence       0.62      0.39      0.48       827\n",
      "\n",
      "   micro avg       0.61      0.35      0.44      2419\n",
      "   macro avg       0.49      0.30      0.36      2419\n",
      "weighted avg       0.54      0.35      0.41      2419\n",
      " samples avg       0.24      0.21      0.21      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   17.3s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   18.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5097971885171857\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5810, Recall: 0.4419, F1-measure: 0.5020\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.35      0.18      0.24       549\n",
      "      murder       0.63      0.55      0.59      1043\n",
      "    violence       0.61      0.47      0.53       827\n",
      "\n",
      "   micro avg       0.58      0.44      0.50      2419\n",
      "   macro avg       0.53      0.40      0.45      2419\n",
      "weighted avg       0.56      0.44      0.49      2419\n",
      " samples avg       0.28      0.26      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   15.9s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   16.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-07, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4927641554524032\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5224, Recall: 0.4299, F1-measure: 0.4717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.28      0.18      0.22       549\n",
      "      murder       0.59      0.55      0.57      1043\n",
      "    violence       0.55      0.44      0.49       827\n",
      "\n",
      "   micro avg       0.52      0.43      0.47      2419\n",
      "   macro avg       0.47      0.39      0.43      2419\n",
      "weighted avg       0.51      0.43      0.46      2419\n",
      " samples avg       0.27      0.25      0.25      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-07,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93254)   (11027, 3)\n",
      "(2730, 93254)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(3,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   22.7s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   23.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4493192086479685\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6047, Recall: 0.3605, F1-measure: 0.4517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.24      0.03      0.05       549\n",
      "      murder       0.64      0.51      0.56      1043\n",
      "    violence       0.60      0.40      0.48       827\n",
      "\n",
      "   micro avg       0.60      0.36      0.45      2419\n",
      "   macro avg       0.49      0.31      0.36      2419\n",
      "weighted avg       0.53      0.36      0.42      2419\n",
      " samples avg       0.25      0.21      0.22      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   20.1s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   25.1s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   25.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4900702374952076\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5800, Recall: 0.4539, F1-measure: 0.5093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.36      0.18      0.24       549\n",
      "      murder       0.61      0.60      0.60      1043\n",
      "    violence       0.63      0.45      0.53       827\n",
      "\n",
      "   micro avg       0.58      0.45      0.51      2419\n",
      "   macro avg       0.53      0.41      0.46      2419\n",
      "weighted avg       0.56      0.45      0.49      2419\n",
      " samples avg       0.28      0.26      0.26      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   16.7s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   20.6s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-09, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5000366630175914\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7,10**-8,10**-9],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4841, Recall: 0.5176, F1-measure: 0.5003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.29      0.25      0.27       549\n",
      "      murder       0.58      0.54      0.56      1043\n",
      "    violence       0.48      0.67      0.56       827\n",
      "\n",
      "   micro avg       0.48      0.52      0.50      2419\n",
      "   macro avg       0.45      0.49      0.46      2419\n",
      "weighted avg       0.48      0.52      0.49      2419\n",
      " samples avg       0.30      0.30      0.28      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-09,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and bi,tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93963)   (11027, 3)\n",
      "(2730, 93963)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   24.0s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   25.6s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.4334337353218364\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6189, Recall: 0.3357, F1-measure: 0.4353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.27      0.02      0.04       549\n",
      "      murder       0.64      0.48      0.55      1043\n",
      "    violence       0.63      0.36      0.46       827\n",
      "\n",
      "   micro avg       0.62      0.34      0.44      2419\n",
      "   macro avg       0.51      0.29      0.35      2419\n",
      "weighted avg       0.55      0.34      0.40      2419\n",
      " samples avg       0.24      0.20      0.20      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.01),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   29.1s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   34.4s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-07, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.4839952971562758\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5130, Recall: 0.4572, F1-measure: 0.4835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.31      0.12      0.18       549\n",
      "      murder       0.59      0.46      0.52      1043\n",
      "    violence       0.50      0.67      0.57       827\n",
      "\n",
      "   micro avg       0.51      0.46      0.48      2419\n",
      "   macro avg       0.47      0.42      0.42      2419\n",
      "weighted avg       0.50      0.46      0.46      2419\n",
      " samples avg       0.29      0.27      0.26      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-07,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   29.3s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   30.6s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-07, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5062054032918752\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5570, Recall: 0.4543, F1-measure: 0.5005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.40      0.04      0.07       549\n",
      "      murder       0.60      0.57      0.58      1043\n",
      "    violence       0.52      0.58      0.55       827\n",
      "\n",
      "   micro avg       0.56      0.45      0.50      2419\n",
      "   macro avg       0.51      0.40      0.40      2419\n",
      "weighted avg       0.53      0.45      0.46      2419\n",
      " samples avg       0.29      0.26      0.26      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-07,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizing with char and uni,bi,tri,four grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11027, 93990)   (11027, 3)\n",
      "(2730, 93990)   (2730, 3)\n"
     ]
    }
   ],
   "source": [
    "vectorize=TfidfVectorizer(ngram_range=(1,4),analyzer='char')\n",
    "X_train=vectorize.fit_transform(train['CleanedSynopsis'])\n",
    "X_test=vectorize.transform(test['CleanedSynopsis'])\n",
    "\n",
    "print(X_train.shape,\" \",y_train.shape)\n",
    "print(X_test.shape,\" \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   24.9s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   27.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True),\n",
      "          n_jobs=-1))]\n",
      "0.3225946011216488\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [3,3.5,2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6552, Recall: 0.2356, F1-measure: 0.3466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.21      0.01      0.02       549\n",
      "      murder       0.67      0.36      0.47      1043\n",
      "    violence       0.67      0.22      0.34       827\n",
      "\n",
      "   micro avg       0.66      0.24      0.35      2419\n",
      "   macro avg       0.52      0.20      0.28      2419\n",
      "weighted avg       0.57      0.24      0.32      2419\n",
      " samples avg       0.18      0.14      0.15      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB(alpha=0.001),n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   33.2s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   34.1s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   37.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5000461094011961\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='log',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5420, Recall: 0.5014, F1-measure: 0.5209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.32      0.32      0.32       549\n",
      "      murder       0.59      0.74      0.66      1043\n",
      "    violence       0.69      0.32      0.44       827\n",
      "\n",
      "   micro avg       0.54      0.50      0.52      2419\n",
      "   macro avg       0.53      0.46      0.47      2419\n",
      "weighted avg       0.56      0.50      0.51      2419\n",
      " samples avg       0.31      0.30      0.29      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log',alpha=1e-05,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   32.1s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   32.3s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-07, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "0.5095352331004768\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('clf', OneVsRestClassifier(SGDClassifier(loss='hinge',n_jobs=-1))),\n",
    "            ])\n",
    "parameters = {\n",
    "            \"clf__estimator__alpha\": [2,2.5,1,10**-1, 10**-2, 10**-3, 10**-4,10**-5,10**-6,10**-7],\n",
    "            }\n",
    "\n",
    "grid_search_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=10,scoring='f1_micro')\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_cv.best_estimator_.steps)\n",
    "print(grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6068, Recall: 0.3324, F1-measure: 0.4295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   flashback       0.37      0.07      0.11       549\n",
      "      murder       0.61      0.56      0.58      1043\n",
      "    violence       0.66      0.23      0.34       827\n",
      "\n",
      "   micro avg       0.61      0.33      0.43      2419\n",
      "   macro avg       0.55      0.28      0.35      2419\n",
      "weighted avg       0.58      0.33      0.39      2419\n",
      " samples avg       0.24      0.20      0.21      2419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='hinge',alpha=1e-07,n_jobs=-1))\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1_score))\n",
    "print(classification_report(y_test, predictions,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorization with word analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  1,1   |  0.416   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,1   |  0.517   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  1,1   |  0.498   |     1e-05      |\n",
      "|    MultinomialNB     |  2,2   |  0.490   |      0.1       |\n",
      "|  SGDClassifier(log)  |  2,2   |  0.463   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  2,2   |  0.475   |     1e-06      |\n",
      "|    MultinomialNB     |  3,3   |  0.321   |      0.01      |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.377   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.361   |     1e-06      |\n",
      "|    MultinomialNB     |  1,2   |  0.476   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,2   |  0.497   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  1,2   |  0.486   |     1e-06      |\n",
      "|    MultinomialNB     |  1,3   |  0.480   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,3   |  0.500   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  1,3   |  0.503   |     1e-05      |\n",
      "|    MultinomialNB     |  1,4   |  0.480   |      0.01      |\n",
      "|  SGDClassifier(log)  |  1,4   |  0.501   |     1e-06      |\n",
      "| SGDClassifier(hinge) |  1,4   |  0.503   |     1e-05      |\n",
      "+----------------------+--------+----------+----------------+\n",
      "\n",
      "TfidfVectorization with char analyzer\n",
      "+----------------------+--------+----------+----------------+\n",
      "|        Model         | ngrams | f1_score | hyperparameter |\n",
      "+----------------------+--------+----------+----------------+\n",
      "|    MultinomialNB     |  3,3   |  0.283   |     0.0001     |\n",
      "|  SGDClassifier(log)  |  3,3   |  0.540   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  3,3   |  0.504   |     1e-05      |\n",
      "|    MultinomialNB     |  4,4   |  0.443   |      0.01      |\n",
      "|  SGDClassifier(log)  |  4,4   |  0.502   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  4,4   |  0.471   |     1e-07      |\n",
      "|    MultinomialNB     |  3,4   |  0.451   |      0.01      |\n",
      "|  SGDClassifier(log)  |  3,4   |  0.509   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  3,4   |  0.500   |     1e-09      |\n",
      "|    MultinomialNB     |  2,4   |  0.435   |      0.01      |\n",
      "|  SGDClassifier(log)  |  2,4   |  0.435   |      0.01      |\n",
      "| SGDClassifier(hinge) |  2,4   |  0.500   |     1e-07      |\n",
      "|    MultinomialNB     |  1,4   |  0.283   |     0.001      |\n",
      "|  SGDClassifier(log)  |  1,4   |  0.346   |     1e-05      |\n",
      "| SGDClassifier(hinge) |  1,4   |  0.429   |     1e-07      |\n",
      "+----------------------+--------+----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "print(\"TfidfVectorization with word analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','1,1','0.416','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,1','0.517','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,1','0.498','1e-05'])\n",
    "table.add_row(['MultinomialNB','2,2','0.490','0.1'])\n",
    "table.add_row(['SGDClassifier(log)','2,2','0.463','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,2','0.475','1e-06'])\n",
    "table.add_row(['MultinomialNB','3,3','0.321','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.377','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.361','1e-06'])\n",
    "table.add_row(['MultinomialNB','1,2','0.476','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,2','0.497','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,2','0.486','1e-06'])\n",
    "table.add_row(['MultinomialNB','1,3','0.480','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,3','0.500','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,3','0.503','1e-05'])\n",
    "table.add_row(['MultinomialNB','1,4','0.480','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','1,4','0.501','1e-06'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,4','0.503','1e-05'])\n",
    "print(table)\n",
    "print('')\n",
    "table = PrettyTable()\n",
    "print(\"TfidfVectorization with char analyzer\")\n",
    "table.field_names=['Model','ngrams','f1_score','hyperparameter']\n",
    "table.add_row(['MultinomialNB','3,3','0.283','0.0001'])\n",
    "table.add_row(['SGDClassifier(log)','3,3','0.540','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,3','0.504','1e-05'])\n",
    "table.add_row(['MultinomialNB','4,4','0.443','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','4,4','0.502','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','4,4','0.471','1e-07'])\n",
    "table.add_row(['MultinomialNB','3,4','0.451','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','3,4','0.509','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','3,4','0.500','1e-09'])\n",
    "table.add_row(['MultinomialNB','2,4','0.435','0.01'])\n",
    "table.add_row(['SGDClassifier(log)','2,4','0.435','0.01'])\n",
    "table.add_row(['SGDClassifier(hinge)','2,4','0.500','1e-07'])\n",
    "table.add_row(['MultinomialNB','1,4','0.283','0.001'])\n",
    "table.add_row(['SGDClassifier(log)','1,4','0.346','1e-05'])\n",
    "table.add_row(['SGDClassifier(hinge)','1,4','0.429','1e-07'])\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
